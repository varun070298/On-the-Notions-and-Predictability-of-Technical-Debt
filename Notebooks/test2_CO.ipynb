{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de87b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "import tensorflow as tf\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import seaborn as sns\n",
    "from sklearn import ensemble\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import graphviz\n",
    "from sklearn.decomposition import PCA\n",
    "from random import choice\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c34370",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e1150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>Domain</th>\n",
       "      <th>NOP</th>\n",
       "      <th>TLOC</th>\n",
       "      <th>LCOM_01</th>\n",
       "      <th>LCOM_20</th>\n",
       "      <th>LCOM_40</th>\n",
       "      <th>LCOM_50</th>\n",
       "      <th>LCOM_60</th>\n",
       "      <th>LCOM_80</th>\n",
       "      <th>LCOM_99</th>\n",
       "      <th>LCOM_std</th>\n",
       "      <th>DIT_01</th>\n",
       "      <th>DIT_20</th>\n",
       "      <th>DIT_40</th>\n",
       "      <th>DIT_50</th>\n",
       "      <th>DIT_60</th>\n",
       "      <th>DIT_80</th>\n",
       "      <th>DIT_99</th>\n",
       "      <th>DIT_std</th>\n",
       "      <th>CE_01</th>\n",
       "      <th>CE_20</th>\n",
       "      <th>CE_40</th>\n",
       "      <th>CE_50</th>\n",
       "      <th>CE_60</th>\n",
       "      <th>CE_80</th>\n",
       "      <th>CE_99</th>\n",
       "      <th>CE_std</th>\n",
       "      <th>RMI_01</th>\n",
       "      <th>RMI_20</th>\n",
       "      <th>RMI_40</th>\n",
       "      <th>RMI_50</th>\n",
       "      <th>RMI_60</th>\n",
       "      <th>RMI_80</th>\n",
       "      <th>RMI_99</th>\n",
       "      <th>RMI_std</th>\n",
       "      <th>NOM_01</th>\n",
       "      <th>NOM_20</th>\n",
       "      <th>NOM_40</th>\n",
       "      <th>NOM_50</th>\n",
       "      <th>NOM_60</th>\n",
       "      <th>NOM_80</th>\n",
       "      <th>NOM_99</th>\n",
       "      <th>NOM_std</th>\n",
       "      <th>NSF_01</th>\n",
       "      <th>NSF_20</th>\n",
       "      <th>NSF_40</th>\n",
       "      <th>NSF_50</th>\n",
       "      <th>NSF_60</th>\n",
       "      <th>NSF_80</th>\n",
       "      <th>NSF_99</th>\n",
       "      <th>NSF_std</th>\n",
       "      <th>NSM_01</th>\n",
       "      <th>NSM_20</th>\n",
       "      <th>NSM_40</th>\n",
       "      <th>NSM_50</th>\n",
       "      <th>NSM_60</th>\n",
       "      <th>NSM_80</th>\n",
       "      <th>NSM_99</th>\n",
       "      <th>NSM_std</th>\n",
       "      <th>NBD_01</th>\n",
       "      <th>NBD_20</th>\n",
       "      <th>NBD_40</th>\n",
       "      <th>NBD_50</th>\n",
       "      <th>NBD_60</th>\n",
       "      <th>NBD_80</th>\n",
       "      <th>NBD_99</th>\n",
       "      <th>NBD_std</th>\n",
       "      <th>SIX_01</th>\n",
       "      <th>SIX_20</th>\n",
       "      <th>SIX_40</th>\n",
       "      <th>SIX_50</th>\n",
       "      <th>SIX_60</th>\n",
       "      <th>SIX_80</th>\n",
       "      <th>SIX_99</th>\n",
       "      <th>SIX_std</th>\n",
       "      <th>CA_01</th>\n",
       "      <th>CA_20</th>\n",
       "      <th>CA_40</th>\n",
       "      <th>CA_50</th>\n",
       "      <th>CA_60</th>\n",
       "      <th>CA_80</th>\n",
       "      <th>CA_99</th>\n",
       "      <th>CA_std</th>\n",
       "      <th>NOI_01</th>\n",
       "      <th>NOI_20</th>\n",
       "      <th>NOI_40</th>\n",
       "      <th>NOI_50</th>\n",
       "      <th>NOI_60</th>\n",
       "      <th>NOI_80</th>\n",
       "      <th>NOI_99</th>\n",
       "      <th>NOI_std</th>\n",
       "      <th>PAR_01</th>\n",
       "      <th>PAR_20</th>\n",
       "      <th>PAR_40</th>\n",
       "      <th>PAR_50</th>\n",
       "      <th>PAR_60</th>\n",
       "      <th>PAR_80</th>\n",
       "      <th>PAR_99</th>\n",
       "      <th>PAR_std</th>\n",
       "      <th>WMC_01</th>\n",
       "      <th>WMC_20</th>\n",
       "      <th>WMC_40</th>\n",
       "      <th>WMC_50</th>\n",
       "      <th>WMC_60</th>\n",
       "      <th>WMC_80</th>\n",
       "      <th>WMC_99</th>\n",
       "      <th>WMC_std</th>\n",
       "      <th>NOC_01</th>\n",
       "      <th>NOC_20</th>\n",
       "      <th>NOC_40</th>\n",
       "      <th>NOC_50</th>\n",
       "      <th>NOC_60</th>\n",
       "      <th>NOC_80</th>\n",
       "      <th>NOC_99</th>\n",
       "      <th>NOC_std</th>\n",
       "      <th>RMA_01</th>\n",
       "      <th>RMA_20</th>\n",
       "      <th>RMA_40</th>\n",
       "      <th>RMA_50</th>\n",
       "      <th>RMA_60</th>\n",
       "      <th>RMA_80</th>\n",
       "      <th>RMA_99</th>\n",
       "      <th>RMA_std</th>\n",
       "      <th>NORM_01</th>\n",
       "      <th>NORM_20</th>\n",
       "      <th>NORM_40</th>\n",
       "      <th>NORM_50</th>\n",
       "      <th>NORM_60</th>\n",
       "      <th>NORM_80</th>\n",
       "      <th>NORM_99</th>\n",
       "      <th>NORM_std</th>\n",
       "      <th>MLOC_01</th>\n",
       "      <th>MLOC_20</th>\n",
       "      <th>MLOC_40</th>\n",
       "      <th>MLOC_50</th>\n",
       "      <th>MLOC_60</th>\n",
       "      <th>MLOC_80</th>\n",
       "      <th>MLOC_99</th>\n",
       "      <th>MLOC_std</th>\n",
       "      <th>NSC_01</th>\n",
       "      <th>NSC_20</th>\n",
       "      <th>NSC_40</th>\n",
       "      <th>NSC_50</th>\n",
       "      <th>NSC_60</th>\n",
       "      <th>NSC_80</th>\n",
       "      <th>NSC_99</th>\n",
       "      <th>NSC_std</th>\n",
       "      <th>RMD_01</th>\n",
       "      <th>RMD_20</th>\n",
       "      <th>RMD_40</th>\n",
       "      <th>RMD_50</th>\n",
       "      <th>RMD_60</th>\n",
       "      <th>RMD_80</th>\n",
       "      <th>RMD_99</th>\n",
       "      <th>RMD_std</th>\n",
       "      <th>NOF_01</th>\n",
       "      <th>NOF_20</th>\n",
       "      <th>NOF_40</th>\n",
       "      <th>NOF_50</th>\n",
       "      <th>NOF_60</th>\n",
       "      <th>NOF_80</th>\n",
       "      <th>NOF_99</th>\n",
       "      <th>NOF_std</th>\n",
       "      <th>VG_01</th>\n",
       "      <th>VG_20</th>\n",
       "      <th>VG_40</th>\n",
       "      <th>VG_50</th>\n",
       "      <th>VG_60</th>\n",
       "      <th>VG_80</th>\n",
       "      <th>VG_99</th>\n",
       "      <th>VG_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ant-1.8</td>\n",
       "      <td>parsers/generators/make</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.95881</td>\n",
       "      <td>0.349370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.402911</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>72.31</td>\n",
       "      <td>14.612170</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313510</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.81</td>\n",
       "      <td>0.349370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>2.904167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.81</td>\n",
       "      <td>1.712138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.990977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.649377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>340.37</td>\n",
       "      <td>69.706238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.19</td>\n",
       "      <td>1.971234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.926909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>134.86</td>\n",
       "      <td>27.414184</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>105.74</td>\n",
       "      <td>28.016630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.62358</td>\n",
       "      <td>0.147081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.276106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.364365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>6.027298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.89548</td>\n",
       "      <td>0.258122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>4.528603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>3.005299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antlr-3</td>\n",
       "      <td>parsers/generators/make</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.97942</td>\n",
       "      <td>0.315929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.71</td>\n",
       "      <td>1.215004</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>37.05</td>\n",
       "      <td>11.037734</td>\n",
       "      <td>0.04008</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.379568</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>57.42</td>\n",
       "      <td>0.315929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.71</td>\n",
       "      <td>7.835914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.71</td>\n",
       "      <td>2.642318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.909568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.722413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>79.11</td>\n",
       "      <td>22.951665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.863782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.087519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>155.91</td>\n",
       "      <td>36.786419</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>62.63</td>\n",
       "      <td>19.157175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.29160</td>\n",
       "      <td>0.095694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.169242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>69.00</td>\n",
       "      <td>13.293574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.62</td>\n",
       "      <td>10.178750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.1222</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5834</td>\n",
       "      <td>0.6758</td>\n",
       "      <td>0.94260</td>\n",
       "      <td>0.340022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.84</td>\n",
       "      <td>5.267432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.931288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aoi-2.8</td>\n",
       "      <td>3D/graphics/media</td>\n",
       "      <td>23.0</td>\n",
       "      <td>110009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.92600</td>\n",
       "      <td>0.332304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.618856</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>73.60</td>\n",
       "      <td>19.385623</td>\n",
       "      <td>0.00154</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.332304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.166593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.36</td>\n",
       "      <td>2.600284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.940688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.776029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>143.8</td>\n",
       "      <td>275.00</td>\n",
       "      <td>95.388596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1.725191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.777643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>271.59</td>\n",
       "      <td>55.560924</td>\n",
       "      <td>1.22</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>48.0</td>\n",
       "      <td>89.16</td>\n",
       "      <td>25.134578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>0.30066</td>\n",
       "      <td>0.086375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>2.905687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>28.548488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.533198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.5308</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>0.95486</td>\n",
       "      <td>0.333972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>7.041553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>6.597943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>argouml</td>\n",
       "      <td>diagram generator/data visualization</td>\n",
       "      <td>77.0</td>\n",
       "      <td>105806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.047122</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>112.23</td>\n",
       "      <td>23.875123</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.4682</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.311233</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.32</td>\n",
       "      <td>3.228501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.651395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.063408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4.875</td>\n",
       "      <td>1.103546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>36.8</td>\n",
       "      <td>242.38</td>\n",
       "      <td>63.455089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.15</td>\n",
       "      <td>2.599246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.963826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>119.24</td>\n",
       "      <td>24.548792</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>27.8</td>\n",
       "      <td>124.38</td>\n",
       "      <td>27.443400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.87980</td>\n",
       "      <td>0.227323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2.146756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>15.348037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.32</td>\n",
       "      <td>4.148885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.3228</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.6008</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.276914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2.960077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.773031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aspectj</td>\n",
       "      <td>programming language</td>\n",
       "      <td>144.0</td>\n",
       "      <td>501762.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.95890</td>\n",
       "      <td>0.326315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.487915</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>96.60</td>\n",
       "      <td>20.907710</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.2596</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>0.759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328175</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>87.80</td>\n",
       "      <td>0.326315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>14.442027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>5.131094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.253706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.829892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>304.73</td>\n",
       "      <td>63.766405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.30</td>\n",
       "      <td>7.134616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.358673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>379.00</td>\n",
       "      <td>96.778699</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>149.96</td>\n",
       "      <td>32.510640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.1952</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.284773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>5.236845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>23.072296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2.401764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.2404</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.283699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>11.678051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>8.464086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>webmail</td>\n",
       "      <td>tool</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.91700</td>\n",
       "      <td>0.324705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.031657</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>17.28</td>\n",
       "      <td>4.970086</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401150</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>55.24</td>\n",
       "      <td>0.324705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.350334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.88</td>\n",
       "      <td>2.214213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.116658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>1.860</td>\n",
       "      <td>0.359039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50.10</td>\n",
       "      <td>15.717908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>2.292882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.138746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>83.36</td>\n",
       "      <td>32.993646</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>6.595231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.91756</td>\n",
       "      <td>0.262232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.656752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63.50</td>\n",
       "      <td>15.164154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.36</td>\n",
       "      <td>2.564172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.3664</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.6636</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.391863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>2.696785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.352829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>weka-3-</td>\n",
       "      <td>tool</td>\n",
       "      <td>113.0</td>\n",
       "      <td>272611.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.97200</td>\n",
       "      <td>0.361847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.445429</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>47.76</td>\n",
       "      <td>11.303808</td>\n",
       "      <td>0.01848</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>0.6104</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.301390</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0.361847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2.381912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.354510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.198679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.756763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>263.20</td>\n",
       "      <td>86.297774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.80</td>\n",
       "      <td>3.402052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.126444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>194.00</td>\n",
       "      <td>40.047652</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>106.76</td>\n",
       "      <td>21.252813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>0.82028</td>\n",
       "      <td>0.188050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.626390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>23.542312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>8.824719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.83048</td>\n",
       "      <td>0.256629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>5.761324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>4.562522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>xalan-2</td>\n",
       "      <td>parsers/generators/make</td>\n",
       "      <td>89.0</td>\n",
       "      <td>183918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.94319</td>\n",
       "      <td>0.290022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.519831</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>64.84</td>\n",
       "      <td>16.390411</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400586</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.19</td>\n",
       "      <td>0.290022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>258.00</td>\n",
       "      <td>33.679851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>3.087048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.155642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.180708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>35.4</td>\n",
       "      <td>235.56</td>\n",
       "      <td>56.544068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>7.081948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.179693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>224.76</td>\n",
       "      <td>40.959828</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>21.871129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.320533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2.499706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>123.38</td>\n",
       "      <td>36.672996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.38</td>\n",
       "      <td>3.313116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>0.3856</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.346714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>20.00</td>\n",
       "      <td>3.882085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>5.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>xerces-</td>\n",
       "      <td>parsers/generators/make</td>\n",
       "      <td>53.0</td>\n",
       "      <td>125973.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.95045</td>\n",
       "      <td>0.326980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.760483</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>55.40</td>\n",
       "      <td>12.969485</td>\n",
       "      <td>0.00884</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.4606</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.351078</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>62.07</td>\n",
       "      <td>0.326980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.69</td>\n",
       "      <td>9.914115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.45</td>\n",
       "      <td>2.703332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.205325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>161.08</td>\n",
       "      <td>38.600349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.40</td>\n",
       "      <td>7.397927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.260530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>361.07</td>\n",
       "      <td>65.078915</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>69.24</td>\n",
       "      <td>18.014991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.69</td>\n",
       "      <td>3.244688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>111.00</td>\n",
       "      <td>22.938023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.691950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.98388</td>\n",
       "      <td>0.297662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.38</td>\n",
       "      <td>6.719867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>6.237518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>xmojo-5</td>\n",
       "      <td>middleware</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3952.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.92034</td>\n",
       "      <td>0.403642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.651715</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.514496</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449673</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.403642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.40</td>\n",
       "      <td>3.769660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.34</td>\n",
       "      <td>1.533058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.029127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>4.010</td>\n",
       "      <td>0.921691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.831370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.562296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.152822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>22.4</td>\n",
       "      <td>96.40</td>\n",
       "      <td>25.076994</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.691240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.207020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.567227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>16.774866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.359491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.416905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.34</td>\n",
       "      <td>5.516545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.66</td>\n",
       "      <td>3.378297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Project                                Domain    NOP      TLOC  LCOM_01  \\\n",
       "0    ant-1.8               parsers/generators/make  127.0  127559.0      0.0   \n",
       "1    antlr-3               parsers/generators/make   20.0   47443.0      0.0   \n",
       "2    aoi-2.8                     3D/graphics/media   23.0  110009.0      0.0   \n",
       "3    argouml  diagram generator/data visualization   77.0  105806.0      0.0   \n",
       "4    aspectj                  programming language  144.0  501762.0      0.0   \n",
       "..       ...                                   ...    ...       ...      ...   \n",
       "104  webmail                                  tool   19.0   10147.0      0.0   \n",
       "105  weka-3-                                  tool  113.0  272611.0      0.0   \n",
       "106  xalan-2               parsers/generators/make   89.0  183918.0      0.0   \n",
       "107  xerces-               parsers/generators/make   53.0  125973.0      0.0   \n",
       "108  xmojo-5                            middleware   15.0    3952.0      0.0   \n",
       "\n",
       "     LCOM_20  LCOM_40  LCOM_50  LCOM_60  LCOM_80  LCOM_99  LCOM_std  DIT_01  \\\n",
       "0        0.0      0.0    0.000   0.0000   0.6670  0.95881  0.349370     0.0   \n",
       "1        0.0      0.0    0.000   0.0000   0.5000  0.97942  0.315929     0.0   \n",
       "2        0.0      0.0    0.000   0.3330   0.6670  0.92600  0.332304     0.0   \n",
       "3        0.0      0.0    0.000   0.0000   0.0000  0.93164  0.259259     0.0   \n",
       "4        0.0      0.0    0.000   0.0000   0.6000  0.95890  0.326315     0.0   \n",
       "..       ...      ...      ...      ...      ...      ...       ...     ...   \n",
       "104      0.0      0.0    0.000   0.0000   0.5000  0.91700  0.324705     0.0   \n",
       "105      0.0      0.0    0.000   0.0000   0.6670  0.97200  0.361847     0.0   \n",
       "106      0.0      0.0    0.000   0.0000   0.4000  0.94319  0.290022     0.0   \n",
       "107      0.0      0.0    0.000   0.0000   0.5000  0.95045  0.326980     0.0   \n",
       "108      0.0      0.1    0.534   0.7758   0.8684  0.92034  0.403642     0.0   \n",
       "\n",
       "     DIT_20  DIT_40  DIT_50  DIT_60  DIT_80  DIT_99   DIT_std  CE_01  CE_20  \\\n",
       "0       1.0     2.0     2.0     3.0     4.0    5.00  1.402911   0.00    1.0   \n",
       "1       1.0     1.0     2.0     2.0     3.0    5.71  1.215004   0.19    1.0   \n",
       "2       1.0     1.0     1.0     2.0     2.0    7.00  1.618856   0.22    5.0   \n",
       "3       1.0     2.0     2.0     3.0     5.0    8.00  2.047122   0.00    1.0   \n",
       "4       1.0     1.0     1.0     2.0     3.0    7.00  1.487915   0.00    1.0   \n",
       "..      ...     ...     ...     ...     ...     ...       ...    ...    ...   \n",
       "104     1.0     1.0     1.0     1.0     2.0    4.00  1.031657   0.00    1.0   \n",
       "105     1.0     1.0     2.0     2.0     4.0    6.00  1.445429   1.00    3.0   \n",
       "106     1.0     1.0     1.0     2.0     3.0    6.00  1.519831   0.00    1.0   \n",
       "107     1.0     1.0     1.0     2.0     3.0    6.00  1.760483   0.52    1.4   \n",
       "108     1.0     1.0     1.0     1.0     2.0    6.00  1.651715   0.00    0.0   \n",
       "\n",
       "     CE_40  CE_50  CE_60  CE_80   CE_99     CE_std   RMI_01  RMI_20  RMI_40  \\\n",
       "0      2.0    2.0    4.0   10.0   72.31  14.612170  0.00000  0.5710  1.0000   \n",
       "1      2.0    3.0    6.0   15.6   37.05  11.037734  0.04008  0.1822  0.3952   \n",
       "2      9.8   10.0   15.0   32.2   73.60  19.385623  0.00154  0.1564  0.3632   \n",
       "3      3.0    4.0    7.0   16.8  112.23  23.875123  0.00000  0.1076  0.4682   \n",
       "4      4.0    5.5    9.0   19.0   96.60  20.907710  0.00000  0.0992  0.2596   \n",
       "..     ...    ...    ...    ...     ...        ...      ...     ...     ...   \n",
       "104    1.0    1.0    2.0    4.8   17.28   4.970086  0.00000  0.0518  0.1922   \n",
       "105    5.0    6.0    8.0   14.0   47.76  11.303808  0.01848  0.3390  0.6104   \n",
       "106    1.0    2.0    4.0   12.4   64.84  16.390411  0.00000  0.1098  0.3800   \n",
       "107    3.8    4.0    7.0   15.6   55.40  12.969485  0.00884  0.1712  0.4606   \n",
       "108    0.0    1.0    1.0    1.0    1.00   0.514496  0.00000  0.0000  0.5000   \n",
       "\n",
       "     RMI_50  RMI_60  RMI_80  RMI_99   RMI_std  NOM_01  NOM_20  NOM_40  NOM_50  \\\n",
       "0    1.0000  1.0000   1.000     1.0  0.313510    0.00     1.0     3.0     4.0   \n",
       "1    0.5040  0.7530   1.000     1.0  0.379568    0.00     1.0     2.0     4.0   \n",
       "2    0.6250  0.7258   1.000     1.0  0.381112    0.00     1.0     2.0     4.0   \n",
       "3    0.5000  0.5816   0.800     1.0  0.311233    0.00     1.0     2.0     3.0   \n",
       "4    0.3415  0.4832   0.759     1.0  0.328175    0.00     1.0     4.0     5.0   \n",
       "..      ...     ...     ...     ...       ...     ...     ...     ...     ...   \n",
       "104  0.3330  0.4900   1.000     1.0  0.401150    0.28     2.0     3.0     6.0   \n",
       "105  0.7140  0.8036   1.000     1.0  0.301390    0.00     1.0     2.0     3.0   \n",
       "106  0.5040  0.8080   1.000     1.0  0.400586    0.00     1.0     2.0     3.0   \n",
       "107  0.6000  0.7100   0.980     1.0  0.351078    0.00     1.0     3.0     5.0   \n",
       "108  0.5000  0.8000   1.000     1.0  0.449673    0.00     1.6     5.2     6.5   \n",
       "\n",
       "     NOM_60  NOM_80  NOM_99   NOM_std  NSF_01  NSF_20  NSF_40  NSF_50  NSF_60  \\\n",
       "0       5.0    11.0   46.81  0.349370     0.0     0.0     0.0     0.0     0.0   \n",
       "1       5.0    14.0   57.42  0.315929     0.0     0.0     0.0     0.0     0.0   \n",
       "2       6.0    12.0   44.00  0.332304     0.0     0.0     0.0     0.0     0.0   \n",
       "3       4.0     7.0   38.00  0.259259     0.0     0.0     0.0     0.0     0.0   \n",
       "4       7.0    14.0   87.80  0.326315     0.0     0.0     0.0     0.0     0.0   \n",
       "..      ...     ...     ...       ...     ...     ...     ...     ...     ...   \n",
       "104     7.0    11.0   55.24  0.324705     0.0     0.0     0.0     0.0     0.0   \n",
       "105     5.0    13.0   54.00  0.361847     0.0     0.0     0.0     0.0     1.0   \n",
       "106     4.0     9.0   76.19  0.290022     0.0     0.0     0.0     0.0     0.0   \n",
       "107     7.0    13.0   62.07  0.326980     0.0     0.0     0.0     0.0     1.0   \n",
       "108     7.0    13.4   25.00  0.403642     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     NSF_80  NSF_99    NSF_std  NSM_01  NSM_20  NSM_40  NSM_50  NSM_60  \\\n",
       "0       1.0   14.00   2.904167     0.0     0.0     0.0     0.0     0.0   \n",
       "1       0.0   16.71   7.835914     0.0     0.0     0.0     0.0     0.0   \n",
       "2       1.0   14.77   3.166593     0.0     0.0     0.0     0.0     0.0   \n",
       "3       1.0   11.32   3.228501     0.0     0.0     0.0     0.0     0.0   \n",
       "4       1.0   30.00  14.442027     0.0     0.0     0.0     0.0     0.0   \n",
       "..      ...     ...        ...     ...     ...     ...     ...     ...   \n",
       "104     1.4    6.72   1.350334     0.0     0.0     0.0     0.0     0.0   \n",
       "105     1.0   10.00   2.381912     0.0     0.0     0.0     0.0     0.0   \n",
       "106     1.0  258.00  33.679851     0.0     0.0     0.0     0.0     0.0   \n",
       "107     2.0   46.69   9.914115     0.0     0.0     0.0     0.0     0.0   \n",
       "108     0.0   15.40   3.769660     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     NSM_80  NSM_99   NSM_std  NBD_01  NBD_20  NBD_40  NBD_50  NBD_60  NBD_80  \\\n",
       "0       0.0    8.81  1.712138     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "1       0.0    6.71  2.642318     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "2       0.0   14.36  2.600284     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "3       0.0    8.00  1.651395     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "4       1.0   20.00  5.131094     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "..      ...     ...       ...     ...     ...     ...     ...     ...     ...   \n",
       "104     0.0   13.88  2.214213     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "105     1.0    8.00  2.354510     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "106     0.0   10.00  3.087048     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "107     0.0   12.45  2.703332     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "108     1.4    6.34  1.533058     0.0     1.0     1.0     1.0     1.0     2.0   \n",
       "\n",
       "     NBD_99   NBD_std  SIX_01  SIX_20  SIX_40  SIX_50  SIX_60  SIX_80  SIX_99  \\\n",
       "0       5.0  0.990977     0.0     0.0     0.0     0.0   0.067  0.6000   3.000   \n",
       "1       5.0  0.909568     0.0     0.0     0.0     0.0   0.000  0.3330   3.000   \n",
       "2       5.0  0.940688     0.0     0.0     0.0     0.0   0.000  0.5426   4.000   \n",
       "3       5.0  1.063408     0.0     0.0     0.0     0.0   0.000  1.0000   4.875   \n",
       "4       6.0  1.253706     0.0     0.0     0.0     0.0   0.015  0.6670   4.000   \n",
       "..      ...       ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "104     6.0  1.116658     0.0     0.0     0.0     0.0   0.000  0.0926   1.860   \n",
       "105     6.0  1.198679     0.0     0.0     0.0     0.0   0.087  0.7500   2.500   \n",
       "106     6.0  1.155642     0.0     0.0     0.0     0.0   0.000  1.0000   5.000   \n",
       "107     6.0  1.205325     0.0     0.0     0.0     0.0   0.000  0.5710   5.000   \n",
       "108     5.0  1.029127     0.0     0.0     0.0     0.0   0.000  0.0752   4.010   \n",
       "\n",
       "      SIX_std  CA_01  CA_20  CA_40  CA_50  CA_60  CA_80   CA_99     CA_std  \\\n",
       "0    0.649377    0.0    0.0    0.0    0.0    0.0    4.0  340.37  69.706238   \n",
       "1    0.722413    0.0    0.0    2.0    2.5    8.0   30.0   79.11  22.951665   \n",
       "2    0.776029    0.0    0.0    4.0    9.0   23.0  143.8  275.00  95.388596   \n",
       "3    1.103546    0.0    1.0    3.0    4.0    7.2   36.8  242.38  63.455089   \n",
       "4    0.829892    0.0    1.0    4.8    8.5   16.0   56.0  304.73  63.766405   \n",
       "..        ...    ...    ...    ...    ...    ...    ...     ...        ...   \n",
       "104  0.359039    0.0    0.0    2.0    3.0   10.0   21.0   50.10  15.717908   \n",
       "105  0.756763    0.0    0.0    1.0    2.0    3.0   14.0  263.20  86.297774   \n",
       "106  1.180708    0.0    0.0    2.0    4.0    7.8   35.4  235.56  56.544068   \n",
       "107  0.996672    0.0    0.4    1.0    2.0    4.6   35.2  161.08  38.600349   \n",
       "108  0.921691    0.0    0.0    0.4    1.0    1.0    1.0    2.84   0.831370   \n",
       "\n",
       "     NOI_01  NOI_20  NOI_40  NOI_50  NOI_60  NOI_80  NOI_99   NOI_std  PAR_01  \\\n",
       "0       0.0     0.0     0.0     0.0     0.0     1.0    9.19  1.971234     0.0   \n",
       "1       0.0     0.0     0.0     0.0     0.4     1.2    6.62  1.863782     0.0   \n",
       "2       0.0     0.0     0.8     1.0     1.0     2.6    5.78  1.725191     0.0   \n",
       "3       0.0     0.0     0.0     0.0     0.0     2.0   11.15  2.599246     0.0   \n",
       "4       0.0     0.0     1.0     1.0     2.0     5.0   34.30  7.134616     0.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...       ...     ...   \n",
       "104     0.0     0.0     0.0     0.0     0.0     0.0    8.38  2.292882     0.0   \n",
       "105     0.0     0.0     0.0     0.0     0.0     1.0   15.80  3.402052     0.0   \n",
       "106     0.0     0.0     0.0     0.0     1.0     4.0   30.36  7.081948     0.0   \n",
       "107     0.0     0.0     0.0     0.0     1.0     2.0   35.40  7.397927     0.0   \n",
       "108     0.0     0.0     0.0     0.0     0.0     0.0    1.84  0.562296     0.0   \n",
       "\n",
       "     PAR_20  PAR_40  PAR_50  PAR_60  PAR_80  PAR_99   PAR_std  WMC_01  WMC_20  \\\n",
       "0       0.0     0.0     1.0     1.0     1.0    4.00  0.926909     0.0     2.0   \n",
       "1       0.0     0.0     0.0     1.0     1.0    5.00  1.087519     0.0     1.0   \n",
       "2       0.0     1.0     1.0     1.0     2.0    8.00  1.777643     0.0     1.0   \n",
       "3       0.0     0.0     1.0     1.0     1.0    4.00  0.963826     0.0     2.0   \n",
       "4       0.0     1.0     1.0     1.0     2.0    6.00  1.358673     0.0     2.0   \n",
       "..      ...     ...     ...     ...     ...     ...       ...     ...     ...   \n",
       "104     0.0     0.0     1.0     1.0     2.0    4.00  1.138746     1.0     3.0   \n",
       "105     0.0     0.0     1.0     1.0     1.0    5.00  1.126444     0.0     1.0   \n",
       "106     0.0     1.0     1.0     1.0     2.0    5.00  1.179693     0.0     2.0   \n",
       "107     0.0     1.0     1.0     1.0     2.0    5.00  1.260530     0.0     2.0   \n",
       "108     0.0     0.0     0.0     0.0     1.0    4.06  1.152822     1.0     3.0   \n",
       "\n",
       "     WMC_40  WMC_50  WMC_60  WMC_80  WMC_99    WMC_std  NOC_01  NOC_20  \\\n",
       "0       5.0     7.0    10.0    23.0  134.86  27.414184    1.00     1.0   \n",
       "1       4.0     5.0     9.0    29.2  155.91  36.786419    0.19     1.8   \n",
       "2       5.0    10.0    15.0    37.0  271.59  55.560924    1.22     9.0   \n",
       "3       4.0     6.0     8.0    18.0  119.24  24.548792    0.77     3.0   \n",
       "4       6.0     9.0    14.0    34.0  379.00  96.778699    0.00     4.0   \n",
       "..      ...     ...     ...     ...     ...        ...     ...     ...   \n",
       "104     6.0     9.0    11.0    23.0   83.36  32.993646    1.00     1.0   \n",
       "105     4.0     6.0    11.0    35.0  194.00  40.047652    1.00     3.4   \n",
       "106     4.0     6.0     9.0    22.0  224.76  40.959828    1.00     2.0   \n",
       "107     6.0     9.0    12.0    33.0  361.07  65.078915    1.00     4.0   \n",
       "108     7.4    12.0    13.8    22.4   96.40  25.076994    0.00     1.0   \n",
       "\n",
       "     NOC_40  NOC_50  NOC_60  NOC_80  NOC_99    NOC_std  RMA_01  RMA_20  \\\n",
       "0       3.0     4.0     6.0    14.0  105.74  28.016630     0.0     0.0   \n",
       "1       9.2    14.0    19.0    38.6   62.63  19.157175     0.0     0.0   \n",
       "2      12.0    16.0    18.6    48.0   89.16  25.134578     0.0     0.0   \n",
       "3       4.8     7.0     9.2    27.8  124.38  27.443400     0.0     0.0   \n",
       "4      10.0    14.0    17.2    35.6  149.96  32.510640     0.0     0.0   \n",
       "..      ...     ...     ...     ...     ...        ...     ...     ...   \n",
       "104     2.0     4.0     5.0    10.0   23.10   6.595231     0.0     0.0   \n",
       "105     6.0     9.0    11.2    20.2  106.76  21.252813     0.0     0.0   \n",
       "106     5.0     7.0    10.8    22.0   90.00  21.871129     0.0     0.0   \n",
       "107     8.8    11.0    14.0    33.6   69.24  18.014991     0.0     0.0   \n",
       "108     1.0     1.0     2.0     2.8    6.52   1.691240     0.0     0.0   \n",
       "\n",
       "     RMA_40  RMA_50  RMA_60  RMA_80   RMA_99   RMA_std  NORM_01  NORM_20  \\\n",
       "0    0.0000   0.000  0.0456  0.1726  0.62358  0.147081      0.0      0.0   \n",
       "1    0.0046   0.043  0.0732  0.1560  0.29160  0.095694      0.0      0.0   \n",
       "2    0.0584   0.086  0.1280  0.1532  0.30066  0.086375      0.0      0.0   \n",
       "3    0.0000   0.000  0.0686  0.2462  0.87980  0.227323      0.0      0.0   \n",
       "4    0.1176   0.156  0.1952  0.4056  1.00000  0.284773      0.0      0.0   \n",
       "..      ...     ...     ...     ...      ...       ...      ...      ...   \n",
       "104  0.0000   0.000  0.0000  0.2400  0.91756  0.262232      0.0      0.0   \n",
       "105  0.0000   0.041  0.1138  0.2120  0.82028  0.188050      0.0      0.0   \n",
       "106  0.0000   0.020  0.1054  0.5000  1.00000  0.320533      0.0      0.0   \n",
       "107  0.0000   0.016  0.0918  0.2388  1.00000  0.329073      0.0      0.0   \n",
       "108  0.0000   0.000  0.0000  0.1000  0.50000  0.207020      0.0      0.0   \n",
       "\n",
       "     NORM_40  NORM_50  NORM_60  NORM_80  NORM_99  NORM_std  MLOC_01  MLOC_20  \\\n",
       "0        0.0      0.0      1.0      1.0     5.00  1.276106      0.0      1.0   \n",
       "1        0.0      0.0      0.0      1.0     8.00  2.169242      0.0      1.0   \n",
       "2        0.0      0.0      0.0      1.0    14.00  2.905687      0.0      1.0   \n",
       "3        0.0      0.0      0.0      1.0    12.00  2.146756      0.0      1.0   \n",
       "4        0.0      0.0      1.0      2.0    14.00  5.236845      0.0      1.0   \n",
       "..       ...      ...      ...      ...      ...       ...      ...      ...   \n",
       "104      0.0      0.0      0.0      1.0     2.72  0.656752      0.0      1.0   \n",
       "105      0.0      0.0      1.0      2.0     7.00  1.626390      0.0      1.0   \n",
       "106      0.0      0.0      0.0      1.0    10.00  2.499706      0.0      1.0   \n",
       "107      0.0      0.0      0.0      1.0    14.69  3.244688      0.0      1.0   \n",
       "108      0.0      0.0      0.0      0.4     2.00  0.567227      0.0      1.0   \n",
       "\n",
       "     MLOC_40  MLOC_50  MLOC_60  MLOC_80  MLOC_99   MLOC_std  NSC_01  NSC_20  \\\n",
       "0        1.0      1.0      3.0      8.0    62.00  12.364365     0.0     0.0   \n",
       "1        2.0      5.0      7.0     14.0    69.00  13.293574     0.0     0.0   \n",
       "2        2.0      3.0      5.0     15.0   121.00  28.548488     0.0     0.0   \n",
       "3        1.0      3.0      4.0     10.0    64.00  15.348037     0.0     0.0   \n",
       "4        1.0      2.0      4.0     10.0    86.00  23.072296     0.0     0.0   \n",
       "..       ...      ...      ...      ...      ...        ...     ...     ...   \n",
       "104      1.0      1.0      2.0      8.0    63.50  15.164154     0.0     0.0   \n",
       "105      1.0      2.0      5.0     13.0    98.00  23.542312     0.0     0.0   \n",
       "106      1.0      1.0      3.0     10.0   123.38  36.672996     0.0     0.0   \n",
       "107      1.0      1.0      3.0     10.0   111.00  22.938023     0.0     0.0   \n",
       "108      2.0      4.0      5.0     13.0    94.00  16.774866     0.0     0.0   \n",
       "\n",
       "     NSC_40  NSC_50  NSC_60  NSC_80  NSC_99    NSC_std  RMD_01  RMD_20  \\\n",
       "0       0.0     0.0     0.0     0.0   13.00   6.027298     0.0  0.0000   \n",
       "1       0.0     0.0     0.0     0.0   26.62  10.178750     0.0  0.0138   \n",
       "2       0.0     0.0     0.0     0.0    9.00   2.533198     0.0  0.0392   \n",
       "3       0.0     0.0     0.0     0.0   10.32   4.148885     0.0  0.1292   \n",
       "4       0.0     0.0     0.0     1.0   11.00   2.401764     0.0  0.0830   \n",
       "..      ...     ...     ...     ...     ...        ...     ...     ...   \n",
       "104     0.0     0.0     0.0     1.0   15.36   2.564172     0.0  0.1002   \n",
       "105     0.0     0.0     0.0     0.0   15.00   8.824719     0.0  0.0000   \n",
       "106     0.0     0.0     0.0     1.0   16.38   3.313116     0.0  0.0000   \n",
       "107     0.0     0.0     0.0     1.0    8.00   2.691950     0.0  0.0088   \n",
       "108     0.0     0.0     0.0     0.0    1.00   0.359491     0.0  0.0000   \n",
       "\n",
       "     RMD_40  RMD_50  RMD_60  RMD_80   RMD_99   RMD_std  NOF_01  NOF_20  \\\n",
       "0    0.0000  0.0000  0.1128  0.3330  0.89548  0.258122     0.0     0.0   \n",
       "1    0.1222  0.4000  0.5834  0.6758  0.94260  0.340022     0.0     0.0   \n",
       "2    0.1808  0.2320  0.5308  0.7150  0.95486  0.333972     0.0     0.0   \n",
       "3    0.3228  0.3590  0.4150  0.6008  1.00000  0.276914     0.0     0.0   \n",
       "4    0.2404  0.3285  0.4696  0.6464  1.00000  0.283699     0.0     0.0   \n",
       "..      ...     ...     ...     ...      ...       ...     ...     ...   \n",
       "104  0.3664  0.5500  0.6636  0.9374  1.00000  0.391863     0.0     0.0   \n",
       "105  0.0940  0.2000  0.2708  0.5000  0.83048  0.256629     0.0     0.0   \n",
       "106  0.1250  0.2570  0.3856  0.6418  1.00000  0.346714     0.0     0.0   \n",
       "107  0.1250  0.2170  0.3390  0.6360  0.98388  0.297662     0.0     0.0   \n",
       "108  0.3000  0.5000  0.5000  1.0000  1.00000  0.416905     0.0     0.0   \n",
       "\n",
       "     NOF_40  NOF_50  NOF_60  NOF_80  NOF_99    NOF_std  VG_01  VG_20  VG_40  \\\n",
       "0       0.0     1.0     1.0     4.0   22.00   4.528603    1.0    1.0    1.0   \n",
       "1       0.0     1.0     1.0     3.0   29.84   5.267432    1.0    1.0    1.0   \n",
       "2       0.0     2.0     3.0     9.0   30.00   7.041553    1.0    1.0    1.0   \n",
       "3       0.0     0.0     0.0     2.0   13.00   2.960077    1.0    1.0    1.0   \n",
       "4       1.0     1.0     2.0     4.0   25.00  11.678051    1.0    1.0    1.0   \n",
       "..      ...     ...     ...     ...     ...        ...    ...    ...    ...   \n",
       "104     1.0     1.0     1.0     3.0   11.16   2.696785    1.0    1.0    1.0   \n",
       "105     0.0     0.0     1.0     5.0   28.00   5.761324    1.0    1.0    1.0   \n",
       "106     0.0     0.0     0.0     2.8   20.00   3.882085    1.0    1.0    1.0   \n",
       "107     0.0     0.0     1.0     4.0   31.38   6.719867    1.0    1.0    1.0   \n",
       "108     1.2     3.0     4.0     8.0   20.34   5.516545    1.0    1.0    1.0   \n",
       "\n",
       "     VG_50  VG_60  VG_80  VG_99    VG_std  \n",
       "0      1.0    1.0    2.0  15.00  3.005299  \n",
       "1      1.0    1.0    2.0  15.00  2.931288  \n",
       "2      1.0    2.0    4.0  31.00  6.597943  \n",
       "3      1.0    1.0    3.0  16.00  3.773031  \n",
       "4      1.0    1.0    3.0  27.00  8.464086  \n",
       "..     ...    ...    ...    ...       ...  \n",
       "104    1.0    1.0    2.0  16.00  3.352829  \n",
       "105    1.0    1.0    3.0  21.00  4.562522  \n",
       "106    1.0    1.0    3.0  19.00  5.619500  \n",
       "107    1.0    1.0    3.0  31.00  6.237518  \n",
       "108    1.0    2.0    2.0  13.66  3.378297  \n",
       "\n",
       "[109 rows x 172 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qcc_quant = pd.read_csv('Qcc_quant.csv')\n",
    "Qcc_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66eaae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>SonarQube_debt</th>\n",
       "      <th>Codiga_debt</th>\n",
       "      <th>CodeClimate_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ant-1.8</td>\n",
       "      <td>1431.033333</td>\n",
       "      <td>677.56</td>\n",
       "      <td>5595.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antlr-3</td>\n",
       "      <td>934.400000</td>\n",
       "      <td>737.00</td>\n",
       "      <td>5701.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aoi-2.8</td>\n",
       "      <td>1606.300000</td>\n",
       "      <td>702.66</td>\n",
       "      <td>10842.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>argouml</td>\n",
       "      <td>2277.266667</td>\n",
       "      <td>992.36</td>\n",
       "      <td>11998.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aspectj</td>\n",
       "      <td>6653.583333</td>\n",
       "      <td>3144.50</td>\n",
       "      <td>67848.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>webmail</td>\n",
       "      <td>106.066667</td>\n",
       "      <td>48.60</td>\n",
       "      <td>209.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>weka-3-</td>\n",
       "      <td>24019.166670</td>\n",
       "      <td>1580.20</td>\n",
       "      <td>21832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>xalan-2</td>\n",
       "      <td>2043.733333</td>\n",
       "      <td>1046.26</td>\n",
       "      <td>13372.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>xerces-</td>\n",
       "      <td>1532.333333</td>\n",
       "      <td>916.50</td>\n",
       "      <td>11602.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>xmojo-5</td>\n",
       "      <td>2018.883333</td>\n",
       "      <td>36.36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Project  SonarQube_debt  Codiga_debt  CodeClimate_debt\n",
       "0    ant-1.8     1431.033333       677.56            5595.5\n",
       "1    antlr-3      934.400000       737.00            5701.4\n",
       "2    aoi-2.8     1606.300000       702.66           10842.6\n",
       "3    argouml     2277.266667       992.36           11998.6\n",
       "4    aspectj     6653.583333      3144.50           67848.8\n",
       "..       ...             ...          ...               ...\n",
       "104  webmail      106.066667        48.60             209.7\n",
       "105  weka-3-    24019.166670      1580.20           21832.0\n",
       "106  xalan-2     2043.733333      1046.26           13372.4\n",
       "107  xerces-     1532.333333       916.50           11602.9\n",
       "108  xmojo-5     2018.883333        36.36               0.0\n",
       "\n",
       "[109 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD = pd.read_csv('TD.csv')\n",
    "TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f61b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(y_test,y_pred):\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return MAE,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64534679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(X,y):\n",
    "    start = timer()\n",
    "    data = []\n",
    "    for i in range(1,2501):\n",
    "        \n",
    "        tf.random.set_seed(i)\n",
    "        np.random.seed(i)\n",
    "        keep_Domain = choice([True, False])\n",
    "        do_PCA = choice([True, False])\n",
    "        print(i)\n",
    "        print(keep_Domain)\n",
    "        print(do_PCA)\n",
    "        \n",
    "        if keep_Domain == False:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, np.array(y), test_size=0.25,random_state=i, \n",
    "                                                                stratify=X['Domain'])\n",
    "#             print(X_train.groupby('Domain')['Project'].nunique())\n",
    "#             print(X_test.groupby('Domain')['Project'].nunique())\n",
    "            ytr = y_train.shape\n",
    "            yte = y_test.shape\n",
    "            \n",
    "            X_std = StandardScaler().fit(X_train.iloc[:,2:])\n",
    "            Y_std = StandardScaler().fit(y_train.reshape(-1,1))\n",
    "            X_train_n = X_std.transform(X_train.iloc[:,2:])\n",
    "            y_train_n = Y_std.transform(y_train.reshape(-1,1))\n",
    "            X_test_n = X_std.transform(X_test.iloc[:,2:])\n",
    "            y_test_n = Y_std.transform(y_test.reshape(-1,1))\n",
    "            y_train_n = y_train_n.reshape(ytr)\n",
    "            y_test_n = y_test_n.reshape(yte)\n",
    "            \n",
    "            if do_PCA == True: \n",
    "                X_train_pca = X_train_n\n",
    "                X_test_pca = X_test_n\n",
    "                pca = PCA()\n",
    "                PCA_X_train = pca.fit_transform(X_train_pca)\n",
    "                PCA_X_test = pca.transform(X_test_pca)\n",
    "                \n",
    "                explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "                t = np.cumsum(explained_variance, dtype=float) \n",
    "                x_max = np.argmax(t > 0.95)\n",
    "                \n",
    "                pca = PCA(n_components=x_max)\n",
    "        \n",
    "                X_train_n = pca.fit_transform(X_train_pca)\n",
    "                X_test_n = pca.transform(X_test_pca)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        if keep_Domain == True:\n",
    "            X['Domain'] = pd.factorize(X['Domain'])[0]\n",
    "    \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, np.array(y), test_size=0.25,random_state=i, \n",
    "                                                                stratify=X['Domain'])\n",
    "#             print(X_train.groupby('Domain')['Project'].nunique())\n",
    "#             print(X_test.groupby('Domain')['Project'].nunique())\n",
    "            ytr = y_train.shape\n",
    "            yte = y_test.shape\n",
    "\n",
    "            X_std = StandardScaler().fit(X_train.iloc[:,1:])\n",
    "            Y_std = StandardScaler().fit(y_train.reshape(-1,1))\n",
    "            X_train_n = X_std.transform(X_train.iloc[:,1:])\n",
    "            y_train_n = Y_std.transform(y_train.reshape(-1,1))\n",
    "            X_test_n = X_std.transform(X_test.iloc[:,1:])\n",
    "            y_test_n = Y_std.transform(y_test.reshape(-1,1))\n",
    "\n",
    "            y_train_n = y_train_n.reshape(ytr)\n",
    "            y_test_n = y_test_n.reshape(yte)\n",
    "            \n",
    "            \n",
    "            if do_PCA == True: \n",
    "                X_train_pca = X_train_n\n",
    "                X_test_pca = X_test_n\n",
    "                pca = PCA()\n",
    "                PCA_X_train = pca.fit_transform(X_train_pca)\n",
    "                PCA_X_test = pca.transform(X_test_pca)\n",
    "                \n",
    "                explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "                t = np.cumsum(explained_variance, dtype=float) \n",
    "                x_max = np.argmax(t > 0.95)\n",
    "                \n",
    "                pca = PCA(n_components=x_max)\n",
    "        \n",
    "                X_train_n = pca.fit_transform(X_train_pca)\n",
    "                X_test_n = pca.transform(X_test_pca)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        print(\"\\nRF\")\n",
    "        #Gridsearch\n",
    "        rf = RandomForestRegressor()\n",
    "        rf_param_grid = {\n",
    "            'bootstrap': [ False],\n",
    "            'max_depth': [5,10,50,80],\n",
    "            'max_features': [2, 3,4,5],\n",
    "            'min_samples_leaf': [2,3,4,5,6],\n",
    "            'min_samples_split': [2,3,4,6,8],\n",
    "            'criterion': ['absolute_error'],\n",
    "            'n_estimators': [1, 5, 10,15],\n",
    "            'random_state' : [i],\n",
    "            'verbose':[1],\n",
    "        }\n",
    "\n",
    "        rf_grid_search = GridSearchCV(estimator = rf, param_grid = rf_param_grid, cv = 3, n_jobs = -1, verbose = 1)\n",
    "\n",
    "        rf_grid_search.fit(X_train_n, y_train_n)\n",
    "\n",
    "        best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "        rf_pred = best_rf.predict(X_test_n)\n",
    "\n",
    "        rf_pred = Y_std.inverse_transform(rf_pred.reshape(-1,1))\n",
    "\n",
    "        rf_pred = rf_pred.reshape(yte)\n",
    "\n",
    "        rf_statis = statistics(y_test,rf_pred)\n",
    "\n",
    "        data.append({\"Seed\": i,'Model_type' : 'RF','Model': rf_grid_search.best_params_,'Domain':keep_Domain, 'PCA':do_PCA,\n",
    "                     'RMSE':rf_statis[1] ,'MAE':rf_statis[0]})\n",
    "        \n",
    "        print(\"\\nxgb\")\n",
    "#     grid_search\n",
    "        xgb_param_grid = {\n",
    "            'loss': [ 'absolute_error','squared_error'],\n",
    "            \"learning_rate\": [0.01,0.12,0.13,0.14],\n",
    "            \"n_estimators\": [10,25,50,80, 100],\n",
    "            \"min_samples_split\": [0.5,2,3,4],\n",
    "            \"max_depth\": [2,4,6,8,10],\n",
    "            \"verbose\":[1],\n",
    "            'random_state' : [i],\n",
    "        }\n",
    "\n",
    "        xgb = ensemble.GradientBoostingRegressor()\n",
    "        xgb_grid_search = GridSearchCV(estimator = xgb, param_grid = xgb_param_grid, cv = 3, n_jobs = -1, verbose = 1)\n",
    "        xgb_grid_search.fit(X_train_n, y_train_n)\n",
    "\n",
    "        xgb_bes = xgb_grid_search.best_estimator_\n",
    "\n",
    "        xgb_pred = xgb_bes.predict(X_test_n)\n",
    "\n",
    "        xgb_pred = Y_std.inverse_transform(xgb_pred.reshape(-1,1))\n",
    "\n",
    "        xgb_pred = xgb_pred.reshape(yte)\n",
    "\n",
    "        xgb_statis = statistics(y_test,xgb_pred)\n",
    "        \n",
    "        data.append({\"Seed\": i,'Model_type' : 'XGB','Model': xgb_grid_search.best_params_,'Domain':keep_Domain, 'PCA':do_PCA,\n",
    "                     'RMSE':xgb_statis[1] ,'MAE':xgb_statis[0]})\n",
    "        \n",
    "        \n",
    "        print(\"\\nmlp\")\n",
    "        mlp_param_grid = {\n",
    "            'hidden_layer_sizes': [(64,16), (64,8), (32,16),(32,8),(16,4)],\n",
    "            'max_iter': [50, 100, 150],\n",
    "            'activation': ['relu'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive']\n",
    "        }\n",
    "        \n",
    "        mlp_reg = MLPRegressor()\n",
    "        \n",
    "        mlp_grid_search = GridSearchCV(mlp_reg, mlp_param_grid, n_jobs= -1, cv=3, verbose = 1)\n",
    "        \n",
    "        mlp_grid_search.fit(X_train_n, y_train_n)\n",
    "\n",
    "        mlp_bes = mlp_grid_search.best_estimator_\n",
    "\n",
    "        mlp_pred = mlp_bes.predict(X_test_n)\n",
    "\n",
    "        mlp_pred = Y_std.inverse_transform(mlp_pred.reshape(-1,1))\n",
    "\n",
    "        mlp_pred = mlp_pred.reshape(yte)\n",
    "\n",
    "        mlp_statis = statistics(y_test,mlp_pred)\n",
    "        \n",
    "        data.append({\"Seed\": i,'Model_type' : 'MLP','Model': mlp_grid_search.best_params_,'Domain':keep_Domain, 'PCA':do_PCA,\n",
    "                     'RMSE':mlp_statis[1] ,'MAE':mlp_statis[0]})\n",
    "        \n",
    "        print(\"\\nlr\")\n",
    "        lr = LinearRegression()\n",
    "        lr_param_grid = {\n",
    "            'fit_intercept':[True,False],\n",
    "            'n_jobs':[-1],\n",
    "            'copy_X':[True, False]\n",
    "        }\n",
    "        lr_grid_search = GridSearchCV(estimator = lr, param_grid = lr_param_grid, cv = 3, n_jobs = -1, verbose = 1)\n",
    "        lr_grid_search.fit(X_train_n, y_train_n)\n",
    "\n",
    "        lr_bes = lr_grid_search.best_estimator_\n",
    "\n",
    "        lr_pred = lr_bes.predict(X_test_n)\n",
    "\n",
    "        lr_pred = Y_std.inverse_transform(lr_pred.reshape(-1,1))\n",
    "\n",
    "        lr_pred = lr_pred.reshape(yte)\n",
    "\n",
    "        lr_statis = statistics(y_test,lr_pred)\n",
    "        \n",
    "        data.append({\"Seed\": i,'Model_type' : 'LR','Model': lr_grid_search.best_params_,'Domain':keep_Domain, 'PCA':do_PCA,\n",
    "                     'RMSE':lr_statis[1] ,'MAE':lr_statis[0]})\n",
    "\n",
    "        \n",
    "    df = pd.DataFrame.from_records(data)\n",
    "    end = timer()\n",
    "    print(end - start)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca713057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7739            0.05s\n",
      "         2           0.6014            0.06s\n",
      "         3           0.4701            0.05s\n",
      "         4           0.3700            0.05s\n",
      "         5           0.2938            0.05s\n",
      "         6           0.2349            0.04s\n",
      "         7           0.1888            0.04s\n",
      "         8           0.1533            0.04s\n",
      "         9           0.1256            0.04s\n",
      "        10           0.1036            0.04s\n",
      "        20           0.0213            0.01s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "2\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3202            0.59s\n",
      "         2           0.3007            0.54s\n",
      "         3           0.2847            0.52s\n",
      "         4           0.2681            0.53s\n",
      "         5           0.2569            0.51s\n",
      "         6           0.2476            0.52s\n",
      "         7           0.2373            0.50s\n",
      "         8           0.2281            0.49s\n",
      "         9           0.2212            0.49s\n",
      "        10           0.2132            0.49s\n",
      "        20           0.1818            0.42s\n",
      "        30           0.1445            0.37s\n",
      "        40           0.1391            0.31s\n",
      "        50           0.1361            0.26s\n",
      "        60           0.1315            0.21s\n",
      "        70           0.1279            0.15s\n",
      "        80           0.1262            0.10s\n",
      "        90           0.1217            0.05s\n",
      "       100           0.1187            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "3\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5068            0.40s\n",
      "         2           0.4684            0.39s\n",
      "         3           0.4360            0.39s\n",
      "         4           0.4132            0.38s\n",
      "         5           0.3904            0.38s\n",
      "         6           0.3725            0.37s\n",
      "         7           0.3591            0.38s\n",
      "         8           0.3422            0.39s\n",
      "         9           0.3293            0.39s\n",
      "        10           0.3116            0.39s\n",
      "        20           0.2187            0.31s\n",
      "        30           0.1721            0.26s\n",
      "        40           0.1621            0.21s\n",
      "        50           0.1538            0.15s\n",
      "        60           0.1388            0.10s\n",
      "        70           0.1241            0.05s\n",
      "        80           0.1102            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "4\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3177            0.40s\n",
      "         2           0.3006            0.47s\n",
      "         3           0.2861            0.46s\n",
      "         4           0.2766            0.49s\n",
      "         5           0.2648            0.50s\n",
      "         6           0.2520            0.51s\n",
      "         7           0.2418            0.52s\n",
      "         8           0.2365            0.51s\n",
      "         9           0.2310            0.51s\n",
      "        10           0.2242            0.50s\n",
      "        20           0.1734            0.44s\n",
      "        30           0.1370            0.37s\n",
      "        40           0.1290            0.29s\n",
      "        50           0.1225            0.23s\n",
      "        60           0.1092            0.15s\n",
      "        70           0.0949            0.08s\n",
      "        80           0.0661            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "5\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7835            0.20s\n",
      "         2           0.6234            0.20s\n",
      "         3           0.4748            0.23s\n",
      "         4           0.3636            0.27s\n",
      "         5           0.2874            0.29s\n",
      "         6           0.2231            0.29s\n",
      "         7           0.1741            0.30s\n",
      "         8           0.1387            0.29s\n",
      "         9           0.1115            0.30s\n",
      "        10           0.0888            0.30s\n",
      "        20           0.0145            0.28s\n",
      "        30           0.0051            0.24s\n",
      "        40           0.0023            0.20s\n",
      "        50           0.0011            0.17s\n",
      "        60           0.0005            0.13s\n",
      "        70           0.0003            0.10s\n",
      "        80           0.0001            0.07s\n",
      "        90           0.0001            0.03s\n",
      "       100           0.0000            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "6\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3263            0.47s\n",
      "         2           0.3057            0.47s\n",
      "         3           0.2909            0.51s\n",
      "         4           0.2807            0.48s\n",
      "         5           0.2704            0.47s\n",
      "         6           0.2623            0.46s\n",
      "         7           0.2509            0.46s\n",
      "         8           0.2427            0.46s\n",
      "         9           0.2357            0.45s\n",
      "        10           0.2284            0.43s\n",
      "        20           0.1607            0.37s\n",
      "        30           0.1398            0.31s\n",
      "        40           0.1232            0.25s\n",
      "        50           0.1209            0.19s\n",
      "        60           0.0990            0.12s\n",
      "        70           0.0820            0.06s\n",
      "        80           0.0796            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "7\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3627            0.47s\n",
      "         2           0.3470            0.47s\n",
      "         3           0.3359            0.44s\n",
      "         4           0.3206            0.42s\n",
      "         5           0.3121            0.39s\n",
      "         6           0.3020            0.39s\n",
      "         7           0.2908            0.39s\n",
      "         8           0.2820            0.38s\n",
      "         9           0.2740            0.37s\n",
      "        10           0.2647            0.36s\n",
      "        20           0.2114            0.30s\n",
      "        30           0.1570            0.25s\n",
      "        40           0.1408            0.20s\n",
      "        50           0.1275            0.15s\n",
      "        60           0.1097            0.10s\n",
      "        70           0.1021            0.05s\n",
      "        80           0.0987            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "8\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7860            0.36s\n",
      "         2           0.6203            0.35s\n",
      "         3           0.4885            0.36s\n",
      "         4           0.3889            0.34s\n",
      "         5           0.3057            0.34s\n",
      "         6           0.2420            0.36s\n",
      "         7           0.1907            0.38s\n",
      "         8           0.1509            0.37s\n",
      "         9           0.1203            0.37s\n",
      "        10           0.0960            0.37s\n",
      "        20           0.0119            0.39s\n",
      "        30           0.0026            0.35s\n",
      "        40           0.0009            0.30s\n",
      "        50           0.0005            0.24s\n",
      "        60           0.0003            0.18s\n",
      "        70           0.0002            0.13s\n",
      "        80           0.0001            0.08s\n",
      "        90           0.0001            0.04s\n",
      "       100           0.0000            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "9\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7844            0.10s\n",
      "         2           0.6198            0.12s\n",
      "         3           0.4961            0.11s\n",
      "         4           0.3991            0.10s\n",
      "         5           0.3249            0.11s\n",
      "         6           0.2628            0.10s\n",
      "         7           0.2160            0.10s\n",
      "         8           0.1774            0.10s\n",
      "         9           0.1475            0.10s\n",
      "        10           0.1244            0.10s\n",
      "        20           0.0343            0.07s\n",
      "        30           0.0162            0.05s\n",
      "        40           0.0091            0.02s\n",
      "        50           0.0050            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "10\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7863            0.24s\n",
      "         2           0.6358            0.22s\n",
      "         3           0.4904            0.22s\n",
      "         4           0.3823            0.24s\n",
      "         5           0.3144            0.23s\n",
      "         6           0.2499            0.24s\n",
      "         7           0.1995            0.24s\n",
      "         8           0.1611            0.24s\n",
      "         9           0.1296            0.23s\n",
      "        10           0.1100            0.23s\n",
      "        20           0.0217            0.21s\n",
      "        30           0.0086            0.17s\n",
      "        40           0.0041            0.13s\n",
      "        50           0.0023            0.09s\n",
      "        60           0.0014            0.06s\n",
      "        70           0.0007            0.03s\n",
      "        80           0.0004            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "11\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3541            0.46s\n",
      "         2           0.3358            0.46s\n",
      "         3           0.3191            0.44s\n",
      "         4           0.3004            0.41s\n",
      "         5           0.2854            0.42s\n",
      "         6           0.2725            0.46s\n",
      "         7           0.2659            0.45s\n",
      "         8           0.2476            0.46s\n",
      "         9           0.2392            0.47s\n",
      "        10           0.2262            0.48s\n",
      "        20           0.1882            0.45s\n",
      "        30           0.1732            0.41s\n",
      "        40           0.1677            0.35s\n",
      "        50           0.1667            0.29s\n",
      "        60           0.1648            0.23s\n",
      "        70           0.1571            0.18s\n",
      "        80           0.1450            0.12s\n",
      "        90           0.1269            0.06s\n",
      "       100           0.1209            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "12\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3251            0.24s\n",
      "         2           0.3103            0.23s\n",
      "         3           0.2957            0.28s\n",
      "         4           0.2857            0.27s\n",
      "         5           0.2769            0.27s\n",
      "         6           0.2688            0.26s\n",
      "         7           0.2638            0.25s\n",
      "         8           0.2571            0.25s\n",
      "         9           0.2452            0.24s\n",
      "        10           0.2357            0.24s\n",
      "        20           0.2005            0.20s\n",
      "        30           0.1901            0.19s\n",
      "        40           0.1816            0.15s\n",
      "        50           0.1785            0.12s\n",
      "        60           0.1760            0.08s\n",
      "        70           0.1745            0.04s\n",
      "        80           0.1736            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "13\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3363            0.62s\n",
      "         2           0.3170            0.59s\n",
      "         3           0.2996            0.63s\n",
      "         4           0.2859            0.60s\n",
      "         5           0.2730            0.61s\n",
      "         6           0.2609            0.62s\n",
      "         7           0.2472            0.61s\n",
      "         8           0.2357            0.61s\n",
      "         9           0.2243            0.61s\n",
      "        10           0.2178            0.60s\n",
      "        20           0.1777            0.55s\n",
      "        30           0.1707            0.47s\n",
      "        40           0.1655            0.40s\n",
      "        50           0.1606            0.33s\n",
      "        60           0.1567            0.27s\n",
      "        70           0.1421            0.20s\n",
      "        80           0.1264            0.13s\n",
      "        90           0.1237            0.07s\n",
      "       100           0.1179            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "14\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3395            0.25s\n",
      "         2           0.3245            0.24s\n",
      "         3           0.3071            0.27s\n",
      "         4           0.2922            0.24s\n",
      "         5           0.2750            0.25s\n",
      "         6           0.2615            0.26s\n",
      "         7           0.2393            0.26s\n",
      "         8           0.2231            0.27s\n",
      "         9           0.2177            0.26s\n",
      "        10           0.2122            0.26s\n",
      "        20           0.1787            0.21s\n",
      "        30           0.1649            0.14s\n",
      "        40           0.1527            0.07s\n",
      "        50           0.1276            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "15\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3400            0.32s\n",
      "         2           0.3213            0.39s\n",
      "         3           0.3041            0.36s\n",
      "         4           0.2883            0.36s\n",
      "         5           0.2769            0.39s\n",
      "         6           0.2646            0.41s\n",
      "         7           0.2529            0.42s\n",
      "         8           0.2367            0.43s\n",
      "         9           0.2245            0.44s\n",
      "        10           0.2112            0.46s\n",
      "        20           0.1707            0.45s\n",
      "        30           0.1545            0.41s\n",
      "        40           0.1509            0.33s\n",
      "        50           0.1457            0.24s\n",
      "        60           0.1398            0.16s\n",
      "        70           0.1038            0.08s\n",
      "        80           0.0892            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "16\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3401            0.07s\n",
      "         2           0.3289            0.07s\n",
      "         3           0.3219            0.07s\n",
      "         4           0.3101            0.07s\n",
      "         5           0.3016            0.06s\n",
      "         6           0.2983            0.06s\n",
      "         7           0.2917            0.06s\n",
      "         8           0.2886            0.05s\n",
      "         9           0.2842            0.05s\n",
      "        10           0.2790            0.05s\n",
      "        20           0.2579            0.01s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "17\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5143            0.59s\n",
      "         2           0.4793            0.54s\n",
      "         3           0.4468            0.58s\n",
      "         4           0.3973            0.55s\n",
      "         5           0.3725            0.55s\n",
      "         6           0.3447            0.56s\n",
      "         7           0.3281            0.54s\n",
      "         8           0.3106            0.54s\n",
      "         9           0.2983            0.54s\n",
      "        10           0.2753            0.53s\n",
      "        20           0.1871            0.51s\n",
      "        30           0.1614            0.46s\n",
      "        40           0.1510            0.39s\n",
      "        50           0.1420            0.33s\n",
      "        60           0.1258            0.26s\n",
      "        70           0.1111            0.20s\n",
      "        80           0.1063            0.13s\n",
      "        90           0.1033            0.07s\n",
      "       100           0.0830            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "18\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7644            0.10s\n",
      "         2           0.5902            0.12s\n",
      "         3           0.4591            0.11s\n",
      "         4           0.3572            0.10s\n",
      "         5           0.2831            0.11s\n",
      "         6           0.2242            0.10s\n",
      "         7           0.1804            0.10s\n",
      "         8           0.1476            0.10s\n",
      "         9           0.1218            0.10s\n",
      "        10           0.1015            0.10s\n",
      "        20           0.0296            0.07s\n",
      "        30           0.0143            0.05s\n",
      "        40           0.0085            0.02s\n",
      "        50           0.0054            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "19\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3352            0.12s\n",
      "         2           0.3193            0.12s\n",
      "         3           0.3034            0.11s\n",
      "         4           0.2872            0.11s\n",
      "         5           0.2755            0.11s\n",
      "         6           0.2638            0.11s\n",
      "         7           0.2564            0.11s\n",
      "         8           0.2460            0.10s\n",
      "         9           0.2373            0.10s\n",
      "        10           0.2303            0.09s\n",
      "        20           0.1757            0.03s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "20\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5411            0.15s\n",
      "         2           0.5208            0.12s\n",
      "         3           0.5049            0.13s\n",
      "         4           0.4887            0.13s\n",
      "         5           0.4721            0.12s\n",
      "         6           0.4532            0.12s\n",
      "         7           0.4430            0.11s\n",
      "         8           0.4275            0.11s\n",
      "         9           0.4131            0.10s\n",
      "        10           0.4010            0.10s\n",
      "        20           0.3451            0.08s\n",
      "        30           0.3172            0.05s\n",
      "        40           0.3042            0.03s\n",
      "        50           0.2986            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "21\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7570            0.05s\n",
      "         2           0.5732            0.05s\n",
      "         3           0.4339            0.05s\n",
      "         4           0.3286            0.04s\n",
      "         5           0.2488            0.03s\n",
      "         6           0.1884            0.03s\n",
      "         7           0.1427            0.02s\n",
      "         8           0.1081            0.01s\n",
      "         9           0.0818            0.01s\n",
      "        10           0.0620            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "22\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3092            0.29s\n",
      "         2           0.2954            0.26s\n",
      "         3           0.2837            0.25s\n",
      "         4           0.2703            0.26s\n",
      "         5           0.2574            0.24s\n",
      "         6           0.2457            0.24s\n",
      "         7           0.2361            0.23s\n",
      "         8           0.2273            0.23s\n",
      "         9           0.2198            0.24s\n",
      "        10           0.2160            0.24s\n",
      "        20           0.1656            0.21s\n",
      "        30           0.1414            0.14s\n",
      "        40           0.1063            0.07s\n",
      "        50           0.0868            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "23\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2984            0.40s\n",
      "         2           0.2835            0.49s\n",
      "         3           0.2656            0.55s\n",
      "         4           0.2558            0.55s\n",
      "         5           0.2424            0.57s\n",
      "         6           0.2333            0.56s\n",
      "         7           0.2232            0.58s\n",
      "         8           0.2195            0.59s\n",
      "         9           0.2120            0.60s\n",
      "        10           0.2084            0.59s\n",
      "        20           0.1669            0.54s\n",
      "        30           0.1492            0.50s\n",
      "        40           0.1222            0.44s\n",
      "        50           0.0923            0.37s\n",
      "        60           0.0753            0.30s\n",
      "        70           0.0623            0.23s\n",
      "        80           0.0610            0.15s\n",
      "        90           0.0593            0.08s\n",
      "       100           0.0442            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "24\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3318            0.51s\n",
      "         2           0.3154            0.50s\n",
      "         3           0.3004            0.56s\n",
      "         4           0.2855            0.53s\n",
      "         5           0.2728            0.54s\n",
      "         6           0.2626            0.55s\n",
      "         7           0.2547            0.57s\n",
      "         8           0.2354            0.57s\n",
      "         9           0.2287            0.58s\n",
      "        10           0.2246            0.59s\n",
      "        20           0.1563            0.58s\n",
      "        30           0.1334            0.53s\n",
      "        40           0.1212            0.47s\n",
      "        50           0.1087            0.39s\n",
      "        60           0.0834            0.32s\n",
      "        70           0.0802            0.24s\n",
      "        80           0.0686            0.16s\n",
      "        90           0.0652            0.08s\n",
      "       100           0.0629            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "25\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3388            0.29s\n",
      "         2           0.3225            0.26s\n",
      "         3           0.3078            0.28s\n",
      "         4           0.2946            0.29s\n",
      "         5           0.2814            0.28s\n",
      "         6           0.2705            0.27s\n",
      "         7           0.2624            0.28s\n",
      "         8           0.2548            0.29s\n",
      "         9           0.2403            0.29s\n",
      "        10           0.2357            0.29s\n",
      "        20           0.1894            0.26s\n",
      "        30           0.1726            0.18s\n",
      "        40           0.1588            0.09s\n",
      "        50           0.1429            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "26\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3521            0.59s\n",
      "         2           0.3343            0.64s\n",
      "         3           0.3182            0.61s\n",
      "         4           0.3043            0.60s\n",
      "         5           0.2936            0.59s\n",
      "         6           0.2847            0.60s\n",
      "         7           0.2748            0.60s\n",
      "         8           0.2662            0.60s\n",
      "         9           0.2602            0.59s\n",
      "        10           0.2540            0.57s\n",
      "        20           0.1960            0.49s\n",
      "        30           0.1771            0.43s\n",
      "        40           0.1690            0.36s\n",
      "        50           0.1552            0.30s\n",
      "        60           0.1425            0.24s\n",
      "        70           0.1247            0.18s\n",
      "        80           0.1165            0.12s\n",
      "        90           0.1146            0.06s\n",
      "       100           0.1133            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "27\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3385            0.12s\n",
      "         2           0.3189            0.13s\n",
      "         3           0.3012            0.12s\n",
      "         4           0.2906            0.12s\n",
      "         5           0.2806            0.11s\n",
      "         6           0.2684            0.11s\n",
      "         7           0.2576            0.11s\n",
      "         8           0.2493            0.10s\n",
      "         9           0.2317            0.10s\n",
      "        10           0.2280            0.10s\n",
      "        20           0.1724            0.04s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "28\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3126            0.30s\n",
      "         2           0.2950            0.34s\n",
      "         3           0.2837            0.36s\n",
      "         4           0.2732            0.36s\n",
      "         5           0.2628            0.36s\n",
      "         6           0.2522            0.34s\n",
      "         7           0.2432            0.35s\n",
      "         8           0.2366            0.35s\n",
      "         9           0.2347            0.34s\n",
      "        10           0.2330            0.34s\n",
      "        20           0.2033            0.27s\n",
      "        30           0.1949            0.24s\n",
      "        40           0.1854            0.21s\n",
      "        50           0.1837            0.18s\n",
      "        60           0.1784            0.14s\n",
      "        70           0.1682            0.11s\n",
      "        80           0.1675            0.07s\n",
      "        90           0.1670            0.04s\n",
      "       100           0.1662            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "29\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5166            0.50s\n",
      "         2           0.4896            0.59s\n",
      "         3           0.4635            0.55s\n",
      "         4           0.4392            0.55s\n",
      "         5           0.4093            0.51s\n",
      "         6           0.3863            0.52s\n",
      "         7           0.3577            0.51s\n",
      "         8           0.3430            0.51s\n",
      "         9           0.3316            0.50s\n",
      "        10           0.3184            0.49s\n",
      "        20           0.2004            0.42s\n",
      "        30           0.1680            0.37s\n",
      "        40           0.1582            0.32s\n",
      "        50           0.1404            0.27s\n",
      "        60           0.1347            0.21s\n",
      "        70           0.1239            0.16s\n",
      "        80           0.1134            0.10s\n",
      "        90           0.1115            0.05s\n",
      "       100           0.1087            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "30\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5026            0.59s\n",
      "         2           0.4715            0.59s\n",
      "         3           0.4452            0.55s\n",
      "         4           0.4242            0.53s\n",
      "         5           0.4017            0.53s\n",
      "         6           0.3801            0.53s\n",
      "         7           0.3625            0.50s\n",
      "         8           0.3383            0.51s\n",
      "         9           0.3181            0.50s\n",
      "        10           0.3047            0.50s\n",
      "        20           0.2109            0.43s\n",
      "        30           0.1889            0.39s\n",
      "        40           0.1764            0.34s\n",
      "        50           0.1703            0.28s\n",
      "        60           0.1521            0.23s\n",
      "        70           0.1470            0.17s\n",
      "        80           0.1301            0.12s\n",
      "        90           0.1120            0.06s\n",
      "       100           0.0982            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "31\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9806            0.30s\n",
      "         2           0.9617            0.33s\n",
      "         3           0.9431            0.31s\n",
      "         4           0.9249            0.32s\n",
      "         5           0.9070            0.32s\n",
      "         6           0.8895            0.31s\n",
      "         7           0.8723            0.31s\n",
      "         8           0.8555            0.31s\n",
      "         9           0.8390            0.31s\n",
      "        10           0.8229            0.30s\n",
      "        20           0.6779            0.27s\n",
      "        30           0.5593            0.23s\n",
      "        40           0.4616            0.20s\n",
      "        50           0.3803            0.17s\n",
      "        60           0.3134            0.13s\n",
      "        70           0.2584            0.10s\n",
      "        80           0.2132            0.07s\n",
      "        90           0.1763            0.03s\n",
      "       100           0.1459            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "32\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5095            0.16s\n",
      "         2           0.4968            0.20s\n",
      "         3           0.4827            0.18s\n",
      "         4           0.4724            0.17s\n",
      "         5           0.4624            0.18s\n",
      "         6           0.4529            0.19s\n",
      "         7           0.4428            0.18s\n",
      "         8           0.4355            0.18s\n",
      "         9           0.4237            0.18s\n",
      "        10           0.4192            0.17s\n",
      "        20           0.3759            0.15s\n",
      "        30           0.3524            0.12s\n",
      "        40           0.3334            0.10s\n",
      "        50           0.3121            0.08s\n",
      "        60           0.3005            0.05s\n",
      "        70           0.2925            0.03s\n",
      "        80           0.2895            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "33\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3688            0.24s\n",
      "         2           0.3579            0.23s\n",
      "         3           0.3486            0.21s\n",
      "         4           0.3416            0.21s\n",
      "         5           0.3317            0.21s\n",
      "         6           0.3264            0.20s\n",
      "         7           0.3188            0.20s\n",
      "         8           0.3119            0.20s\n",
      "         9           0.3050            0.19s\n",
      "        10           0.3019            0.18s\n",
      "        20           0.2704            0.16s\n",
      "        30           0.2467            0.13s\n",
      "        40           0.2377            0.11s\n",
      "        50           0.2320            0.08s\n",
      "        60           0.2272            0.05s\n",
      "        70           0.2247            0.03s\n",
      "        80           0.2224            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "34\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3289            0.47s\n",
      "         2           0.3119            0.47s\n",
      "         3           0.2969            0.46s\n",
      "         4           0.2820            0.48s\n",
      "         5           0.2694            0.47s\n",
      "         6           0.2572            0.46s\n",
      "         7           0.2482            0.44s\n",
      "         8           0.2399            0.43s\n",
      "         9           0.2324            0.43s\n",
      "        10           0.2254            0.43s\n",
      "        20           0.1769            0.36s\n",
      "        30           0.1500            0.30s\n",
      "        40           0.1402            0.24s\n",
      "        50           0.1368            0.18s\n",
      "        60           0.1352            0.12s\n",
      "        70           0.1346            0.06s\n",
      "        80           0.1310            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "35\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3496            0.29s\n",
      "         2           0.3309            0.29s\n",
      "         3           0.3153            0.31s\n",
      "         4           0.3008            0.33s\n",
      "         5           0.2877            0.32s\n",
      "         6           0.2765            0.31s\n",
      "         7           0.2683            0.29s\n",
      "         8           0.2606            0.29s\n",
      "         9           0.2415            0.29s\n",
      "        10           0.2336            0.28s\n",
      "        20           0.1810            0.20s\n",
      "        30           0.1589            0.13s\n",
      "        40           0.1538            0.06s\n",
      "        50           0.1438            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "36\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3387            0.50s\n",
      "         2           0.3189            0.54s\n",
      "         3           0.3015            0.58s\n",
      "         4           0.2846            0.60s\n",
      "         5           0.2753            0.59s\n",
      "         6           0.2620            0.60s\n",
      "         7           0.2546            0.60s\n",
      "         8           0.2331            0.60s\n",
      "         9           0.2183            0.59s\n",
      "        10           0.2027            0.59s\n",
      "        20           0.1612            0.63s\n",
      "        30           0.1449            0.60s\n",
      "        40           0.1211            0.52s\n",
      "        50           0.1113            0.44s\n",
      "        60           0.1080            0.36s\n",
      "        70           0.0948            0.27s\n",
      "        80           0.0908            0.18s\n",
      "        90           0.0780            0.09s\n",
      "       100           0.0756            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "37\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4990            0.14s\n",
      "         2           0.4682            0.16s\n",
      "         3           0.4333            0.15s\n",
      "         4           0.4040            0.15s\n",
      "         5           0.3815            0.14s\n",
      "         6           0.3593            0.13s\n",
      "         7           0.3414            0.12s\n",
      "         8           0.3255            0.11s\n",
      "         9           0.3139            0.11s\n",
      "        10           0.3021            0.10s\n",
      "        20           0.1883            0.03s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "38\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3304            0.47s\n",
      "         2           0.3137            0.59s\n",
      "         3           0.2857            0.56s\n",
      "         4           0.2711            0.53s\n",
      "         5           0.2596            0.54s\n",
      "         6           0.2509            0.52s\n",
      "         7           0.2429            0.51s\n",
      "         8           0.2368            0.51s\n",
      "         9           0.2303            0.51s\n",
      "        10           0.2242            0.50s\n",
      "        20           0.1796            0.41s\n",
      "        30           0.1354            0.34s\n",
      "        40           0.1133            0.28s\n",
      "        50           0.1085            0.20s\n",
      "        60           0.1017            0.14s\n",
      "        70           0.0922            0.07s\n",
      "        80           0.0891            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "39\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5183            0.40s\n",
      "         2           0.4746            0.49s\n",
      "         3           0.4470            0.49s\n",
      "         4           0.4164            0.46s\n",
      "         5           0.3933            0.48s\n",
      "         6           0.3708            0.47s\n",
      "         7           0.3454            0.47s\n",
      "         8           0.3344            0.45s\n",
      "         9           0.3251            0.43s\n",
      "        10           0.3120            0.42s\n",
      "        20           0.2272            0.38s\n",
      "        30           0.1875            0.33s\n",
      "        40           0.1718            0.28s\n",
      "        50           0.1640            0.24s\n",
      "        60           0.1567            0.19s\n",
      "        70           0.1515            0.14s\n",
      "        80           0.1455            0.10s\n",
      "        90           0.1419            0.05s\n",
      "       100           0.1284            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "40\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5459            0.39s\n",
      "         2           0.5095            0.39s\n",
      "         3           0.4789            0.36s\n",
      "         4           0.4488            0.40s\n",
      "         5           0.4232            0.41s\n",
      "         6           0.4056            0.41s\n",
      "         7           0.3823            0.41s\n",
      "         8           0.3582            0.40s\n",
      "         9           0.3440            0.39s\n",
      "        10           0.3271            0.40s\n",
      "        20           0.2474            0.34s\n",
      "        30           0.2309            0.29s\n",
      "        40           0.2235            0.23s\n",
      "        50           0.2133            0.17s\n",
      "        60           0.2058            0.12s\n",
      "        70           0.2030            0.06s\n",
      "        80           0.1958            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "41\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3240            0.59s\n",
      "         2           0.3088            0.54s\n",
      "         3           0.2931            0.52s\n",
      "         4           0.2792            0.55s\n",
      "         5           0.2678            0.55s\n",
      "         6           0.2590            0.55s\n",
      "         7           0.2524            0.56s\n",
      "         8           0.2416            0.58s\n",
      "         9           0.2329            0.58s\n",
      "        10           0.2279            0.59s\n",
      "        20           0.1699            0.59s\n",
      "        30           0.1513            0.53s\n",
      "        40           0.1139            0.46s\n",
      "        50           0.1004            0.39s\n",
      "        60           0.0834            0.31s\n",
      "        70           0.0728            0.23s\n",
      "        80           0.0701            0.16s\n",
      "        90           0.0681            0.08s\n",
      "       100           0.0662            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "42\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3432            0.15s\n",
      "         2           0.3309            0.12s\n",
      "         3           0.3216            0.13s\n",
      "         4           0.3107            0.12s\n",
      "         5           0.3044            0.11s\n",
      "         6           0.2973            0.11s\n",
      "         7           0.2898            0.11s\n",
      "         8           0.2838            0.11s\n",
      "         9           0.2792            0.11s\n",
      "        10           0.2742            0.11s\n",
      "        20           0.2442            0.08s\n",
      "        30           0.2259            0.06s\n",
      "        40           0.2145            0.03s\n",
      "        50           0.2031            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "43\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3181            0.40s\n",
      "         2           0.3046            0.44s\n",
      "         3           0.2882            0.45s\n",
      "         4           0.2751            0.46s\n",
      "         5           0.2633            0.46s\n",
      "         6           0.2522            0.50s\n",
      "         7           0.2317            0.49s\n",
      "         8           0.2238            0.51s\n",
      "         9           0.2176            0.51s\n",
      "        10           0.2103            0.52s\n",
      "        20           0.1745            0.55s\n",
      "        30           0.1476            0.51s\n",
      "        40           0.1430            0.45s\n",
      "        50           0.1285            0.37s\n",
      "        60           0.1189            0.30s\n",
      "        70           0.1152            0.23s\n",
      "        80           0.1103            0.15s\n",
      "        90           0.1060            0.08s\n",
      "       100           0.1012            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "44\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5320            0.50s\n",
      "         2           0.4974            0.49s\n",
      "         3           0.4688            0.52s\n",
      "         4           0.4354            0.48s\n",
      "         5           0.4146            0.48s\n",
      "         6           0.3974            0.47s\n",
      "         7           0.3803            0.45s\n",
      "         8           0.3642            0.45s\n",
      "         9           0.3447            0.46s\n",
      "        10           0.3321            0.45s\n",
      "        20           0.2357            0.39s\n",
      "        30           0.1712            0.35s\n",
      "        40           0.1355            0.30s\n",
      "        50           0.1197            0.26s\n",
      "        60           0.1123            0.21s\n",
      "        70           0.1072            0.16s\n",
      "        80           0.0911            0.10s\n",
      "        90           0.0830            0.05s\n",
      "       100           0.0803            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "45\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3586            0.50s\n",
      "         2           0.3403            0.59s\n",
      "         3           0.3206            0.55s\n",
      "         4           0.3054            0.55s\n",
      "         5           0.2932            0.55s\n",
      "         6           0.2813            0.53s\n",
      "         7           0.2734            0.53s\n",
      "         8           0.2664            0.53s\n",
      "         9           0.2538            0.54s\n",
      "        10           0.2371            0.52s\n",
      "        20           0.1765            0.49s\n",
      "        30           0.1597            0.44s\n",
      "        40           0.1262            0.38s\n",
      "        50           0.1123            0.31s\n",
      "        60           0.1037            0.25s\n",
      "        70           0.0974            0.19s\n",
      "        80           0.0939            0.12s\n",
      "        90           0.0842            0.06s\n",
      "       100           0.0821            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "46\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3250            0.50s\n",
      "         2           0.3059            0.49s\n",
      "         3           0.2921            0.55s\n",
      "         4           0.2783            0.53s\n",
      "         5           0.2620            0.55s\n",
      "         6           0.2548            0.55s\n",
      "         7           0.2437            0.56s\n",
      "         8           0.2357            0.58s\n",
      "         9           0.2211            0.59s\n",
      "        10           0.2107            0.59s\n",
      "        20           0.1782            0.56s\n",
      "        30           0.1559            0.50s\n",
      "        40           0.1381            0.43s\n",
      "        50           0.1167            0.36s\n",
      "        60           0.1103            0.29s\n",
      "        70           0.0962            0.22s\n",
      "        80           0.0898            0.14s\n",
      "        90           0.0842            0.07s\n",
      "       100           0.0832            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "47\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3010            0.40s\n",
      "         2           0.2893            0.34s\n",
      "         3           0.2781            0.32s\n",
      "         4           0.2631            0.36s\n",
      "         5           0.2559            0.36s\n",
      "         6           0.2452            0.34s\n",
      "         7           0.2387            0.33s\n",
      "         8           0.2303            0.36s\n",
      "         9           0.2210            0.35s\n",
      "        10           0.2157            0.34s\n",
      "        20           0.1835            0.29s\n",
      "        30           0.1747            0.26s\n",
      "        40           0.1705            0.22s\n",
      "        50           0.1629            0.19s\n",
      "        60           0.1616            0.15s\n",
      "        70           0.1574            0.11s\n",
      "        80           0.1565            0.08s\n",
      "        90           0.1561            0.04s\n",
      "       100           0.1559            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "48\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5182            0.26s\n",
      "         2           0.4847            0.26s\n",
      "         3           0.4522            0.25s\n",
      "         4           0.4155            0.24s\n",
      "         5           0.3957            0.23s\n",
      "         6           0.3776            0.23s\n",
      "         7           0.3549            0.22s\n",
      "         8           0.3359            0.21s\n",
      "         9           0.3252            0.21s\n",
      "        10           0.3076            0.21s\n",
      "        20           0.2239            0.15s\n",
      "        30           0.1930            0.10s\n",
      "        40           0.1795            0.05s\n",
      "        50           0.1759            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "49\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3370            0.16s\n",
      "         2           0.3284            0.14s\n",
      "         3           0.3208            0.14s\n",
      "         4           0.3118            0.14s\n",
      "         5           0.3057            0.13s\n",
      "         6           0.3003            0.13s\n",
      "         7           0.2937            0.13s\n",
      "         8           0.2890            0.13s\n",
      "         9           0.2874            0.12s\n",
      "        10           0.2843            0.12s\n",
      "        20           0.2637            0.09s\n",
      "        30           0.2461            0.06s\n",
      "        40           0.2333            0.03s\n",
      "        50           0.2271            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "50\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3430            0.29s\n",
      "         2           0.3207            0.24s\n",
      "         3           0.2987            0.24s\n",
      "         4           0.2789            0.23s\n",
      "         5           0.2638            0.23s\n",
      "         6           0.2467            0.23s\n",
      "         7           0.2358            0.24s\n",
      "         8           0.2272            0.24s\n",
      "         9           0.2171            0.24s\n",
      "        10           0.2062            0.24s\n",
      "        20           0.1766            0.20s\n",
      "        30           0.1633            0.13s\n",
      "        40           0.1488            0.07s\n",
      "        50           0.1427            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "51\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3101            0.57s\n",
      "         2           0.2906            0.59s\n",
      "         3           0.2709            0.58s\n",
      "         4           0.2585            0.57s\n",
      "         5           0.2474            0.57s\n",
      "         6           0.2397            0.56s\n",
      "         7           0.2305            0.56s\n",
      "         8           0.2232            0.55s\n",
      "         9           0.2187            0.56s\n",
      "        10           0.2132            0.56s\n",
      "        20           0.1675            0.49s\n",
      "        30           0.1528            0.44s\n",
      "        40           0.1493            0.38s\n",
      "        50           0.1462            0.31s\n",
      "        60           0.1342            0.25s\n",
      "        70           0.1273            0.19s\n",
      "        80           0.1237            0.13s\n",
      "        90           0.1080            0.06s\n",
      "       100           0.0941            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "52\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3528            0.25s\n",
      "         2           0.3191            0.26s\n",
      "         3           0.2996            0.25s\n",
      "         4           0.2841            0.24s\n",
      "         5           0.2706            0.24s\n",
      "         6           0.2583            0.24s\n",
      "         7           0.2456            0.23s\n",
      "         8           0.2362            0.23s\n",
      "         9           0.2282            0.22s\n",
      "        10           0.2171            0.22s\n",
      "        20           0.1629            0.18s\n",
      "        30           0.1371            0.12s\n",
      "        40           0.1240            0.06s\n",
      "        50           0.1098            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "53\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5401            0.15s\n",
      "         2           0.5234            0.12s\n",
      "         3           0.5094            0.11s\n",
      "         4           0.4953            0.10s\n",
      "         5           0.4658            0.11s\n",
      "         6           0.4547            0.10s\n",
      "         7           0.4454            0.10s\n",
      "         8           0.4370            0.10s\n",
      "         9           0.4312            0.10s\n",
      "        10           0.4250            0.10s\n",
      "        20           0.3856            0.08s\n",
      "        30           0.3647            0.05s\n",
      "        40           0.3374            0.03s\n",
      "        50           0.3059            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "54\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5207            0.24s\n",
      "         2           0.4834            0.23s\n",
      "         3           0.4546            0.23s\n",
      "         4           0.4301            0.25s\n",
      "         5           0.4143            0.24s\n",
      "         6           0.3963            0.23s\n",
      "         7           0.3806            0.24s\n",
      "         8           0.3691            0.24s\n",
      "         9           0.3581            0.24s\n",
      "        10           0.3498            0.23s\n",
      "        20           0.2691            0.23s\n",
      "        30           0.2317            0.19s\n",
      "        40           0.2249            0.15s\n",
      "        50           0.2086            0.11s\n",
      "        60           0.1972            0.08s\n",
      "        70           0.1937            0.04s\n",
      "        80           0.1911            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "55\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3310            0.40s\n",
      "         2           0.3126            0.43s\n",
      "         3           0.2875            0.46s\n",
      "         4           0.2758            0.49s\n",
      "         5           0.2598            0.48s\n",
      "         6           0.2483            0.48s\n",
      "         7           0.2390            0.48s\n",
      "         8           0.2346            0.50s\n",
      "         9           0.2249            0.51s\n",
      "        10           0.2169            0.50s\n",
      "        20           0.1645            0.45s\n",
      "        30           0.1413            0.38s\n",
      "        40           0.1319            0.31s\n",
      "        50           0.1178            0.23s\n",
      "        60           0.0940            0.16s\n",
      "        70           0.0893            0.08s\n",
      "        80           0.0776            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "56\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3253            0.36s\n",
      "         2           0.3088            0.36s\n",
      "         3           0.2921            0.39s\n",
      "         4           0.2793            0.38s\n",
      "         5           0.2659            0.39s\n",
      "         6           0.2544            0.39s\n",
      "         7           0.2443            0.39s\n",
      "         8           0.2352            0.41s\n",
      "         9           0.2279            0.42s\n",
      "        10           0.2213            0.43s\n",
      "        20           0.1760            0.41s\n",
      "        30           0.1508            0.36s\n",
      "        40           0.1387            0.29s\n",
      "        50           0.1351            0.22s\n",
      "        60           0.1308            0.15s\n",
      "        70           0.1231            0.07s\n",
      "        80           0.1067            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "57\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3296            0.40s\n",
      "         2           0.3165            0.43s\n",
      "         3           0.3012            0.44s\n",
      "         4           0.2866            0.42s\n",
      "         5           0.2748            0.42s\n",
      "         6           0.2661            0.41s\n",
      "         7           0.2597            0.42s\n",
      "         8           0.2535            0.43s\n",
      "         9           0.2383            0.44s\n",
      "        10           0.2297            0.44s\n",
      "        20           0.1897            0.43s\n",
      "        30           0.1757            0.37s\n",
      "        40           0.1331            0.31s\n",
      "        50           0.1096            0.23s\n",
      "        60           0.0858            0.16s\n",
      "        70           0.0737            0.08s\n",
      "        80           0.0713            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "58\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3324            0.31s\n",
      "         2           0.3133            0.25s\n",
      "         3           0.2972            0.25s\n",
      "         4           0.2828            0.26s\n",
      "         5           0.2700            0.26s\n",
      "         6           0.2567            0.26s\n",
      "         7           0.2453            0.26s\n",
      "         8           0.2278            0.25s\n",
      "         9           0.2196            0.25s\n",
      "        10           0.2149            0.25s\n",
      "        20           0.1723            0.21s\n",
      "        30           0.1494            0.15s\n",
      "        40           0.1122            0.08s\n",
      "        50           0.0894            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "59\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4901            0.50s\n",
      "         2           0.4632            0.49s\n",
      "         3           0.4429            0.45s\n",
      "         4           0.4224            0.48s\n",
      "         5           0.4021            0.48s\n",
      "         6           0.3848            0.47s\n",
      "         7           0.3747            0.45s\n",
      "         8           0.3634            0.45s\n",
      "         9           0.3528            0.44s\n",
      "        10           0.3384            0.45s\n",
      "        20           0.2741            0.38s\n",
      "        30           0.2435            0.32s\n",
      "        40           0.2359            0.28s\n",
      "        50           0.2268            0.23s\n",
      "        60           0.2159            0.19s\n",
      "        70           0.2005            0.14s\n",
      "        80           0.1946            0.09s\n",
      "        90           0.1904            0.05s\n",
      "       100           0.1754            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "60\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5276            0.59s\n",
      "         2           0.4984            0.54s\n",
      "         3           0.4689            0.52s\n",
      "         4           0.4324            0.53s\n",
      "         5           0.4072            0.51s\n",
      "         6           0.3899            0.52s\n",
      "         7           0.3679            0.50s\n",
      "         8           0.3480            0.49s\n",
      "         9           0.3347            0.50s\n",
      "        10           0.3189            0.50s\n",
      "        20           0.2311            0.45s\n",
      "        30           0.1715            0.39s\n",
      "        40           0.1355            0.34s\n",
      "        50           0.1268            0.29s\n",
      "        60           0.1232            0.23s\n",
      "        70           0.1215            0.17s\n",
      "        80           0.1130            0.12s\n",
      "        90           0.1041            0.06s\n",
      "       100           0.1025            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "61\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3540            0.14s\n",
      "         2           0.3331            0.14s\n",
      "         3           0.3092            0.13s\n",
      "         4           0.2917            0.13s\n",
      "         5           0.2804            0.12s\n",
      "         6           0.2703            0.11s\n",
      "         7           0.2608            0.11s\n",
      "         8           0.2493            0.10s\n",
      "         9           0.2403            0.10s\n",
      "        10           0.2346            0.09s\n",
      "        20           0.1802            0.03s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "62\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3419            0.20s\n",
      "         2           0.3261            0.22s\n",
      "         3           0.3108            0.24s\n",
      "         4           0.2997            0.24s\n",
      "         5           0.2904            0.24s\n",
      "         6           0.2803            0.24s\n",
      "         7           0.2725            0.23s\n",
      "         8           0.2666            0.23s\n",
      "         9           0.2593            0.23s\n",
      "        10           0.2524            0.23s\n",
      "        20           0.1967            0.17s\n",
      "        30           0.1768            0.11s\n",
      "        40           0.1637            0.06s\n",
      "        50           0.1356            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "63\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9808            0.20s\n",
      "         2           0.9621            0.25s\n",
      "         3           0.9437            0.23s\n",
      "         4           0.9256            0.22s\n",
      "         5           0.9080            0.23s\n",
      "         6           0.8906            0.22s\n",
      "         7           0.8737            0.23s\n",
      "         8           0.8570            0.22s\n",
      "         9           0.8407            0.22s\n",
      "        10           0.8247            0.22s\n",
      "        20           0.6803            0.20s\n",
      "        30           0.5616            0.17s\n",
      "        40           0.4644            0.15s\n",
      "        50           0.3846            0.13s\n",
      "        60           0.3187            0.10s\n",
      "        70           0.2645            0.08s\n",
      "        80           0.2199            0.05s\n",
      "        90           0.1831            0.03s\n",
      "       100           0.1528            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "64\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3354            0.20s\n",
      "         2           0.3185            0.24s\n",
      "         3           0.3014            0.25s\n",
      "         4           0.2861            0.26s\n",
      "         5           0.2731            0.27s\n",
      "         6           0.2614            0.28s\n",
      "         7           0.2538            0.28s\n",
      "         8           0.2448            0.27s\n",
      "         9           0.2275            0.28s\n",
      "        10           0.2216            0.28s\n",
      "        20           0.1740            0.23s\n",
      "        30           0.1625            0.16s\n",
      "        40           0.1555            0.08s\n",
      "        50           0.1518            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "65\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3409            0.52s\n",
      "         2           0.3252            0.51s\n",
      "         3           0.3099            0.48s\n",
      "         4           0.2959            0.49s\n",
      "         5           0.2844            0.49s\n",
      "         6           0.2745            0.50s\n",
      "         7           0.2605            0.49s\n",
      "         8           0.2406            0.49s\n",
      "         9           0.2356            0.49s\n",
      "        10           0.2234            0.53s\n",
      "        20           0.1848            0.47s\n",
      "        30           0.1659            0.41s\n",
      "        40           0.1628            0.35s\n",
      "        50           0.1459            0.29s\n",
      "        60           0.1449            0.23s\n",
      "        70           0.1418            0.18s\n",
      "        80           0.1366            0.12s\n",
      "        90           0.1340            0.06s\n",
      "       100           0.1254            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "66\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8298            0.20s\n",
      "         2           0.6981            0.24s\n",
      "         3           0.5696            0.23s\n",
      "         4           0.4698            0.24s\n",
      "         5           0.3978            0.23s\n",
      "         6           0.3330            0.22s\n",
      "         7           0.2815            0.23s\n",
      "         8           0.2428            0.22s\n",
      "         9           0.2111            0.21s\n",
      "        10           0.1821            0.22s\n",
      "        20           0.0631            0.19s\n",
      "        30           0.0320            0.16s\n",
      "        40           0.0178            0.14s\n",
      "        50           0.0116            0.11s\n",
      "        60           0.0080            0.09s\n",
      "        70           0.0056            0.07s\n",
      "        80           0.0042            0.05s\n",
      "        90           0.0031            0.02s\n",
      "       100           0.0024            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "67\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3501            0.30s\n",
      "         2           0.3425            0.25s\n",
      "         3           0.3360            0.26s\n",
      "         4           0.3289            0.24s\n",
      "         5           0.3239            0.23s\n",
      "         6           0.3174            0.24s\n",
      "         7           0.3126            0.24s\n",
      "         8           0.3070            0.23s\n",
      "         9           0.3029            0.22s\n",
      "        10           0.2995            0.23s\n",
      "        20           0.2798            0.19s\n",
      "        30           0.2655            0.17s\n",
      "        40           0.2535            0.14s\n",
      "        50           0.2494            0.12s\n",
      "        60           0.2455            0.09s\n",
      "        70           0.2436            0.07s\n",
      "        80           0.2408            0.05s\n",
      "        90           0.2384            0.02s\n",
      "       100           0.2359            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "68\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8257            0.08s\n",
      "         2           0.6907            0.07s\n",
      "         3           0.5486            0.07s\n",
      "         4           0.4550            0.07s\n",
      "         5           0.3651            0.07s\n",
      "         6           0.2967            0.06s\n",
      "         7           0.2418            0.06s\n",
      "         8           0.1996            0.06s\n",
      "         9           0.1670            0.06s\n",
      "        10           0.1400            0.05s\n",
      "        20           0.0280            0.02s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "69\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3545            0.23s\n",
      "         2           0.3358            0.24s\n",
      "         3           0.3209            0.24s\n",
      "         4           0.3067            0.25s\n",
      "         5           0.2935            0.25s\n",
      "         6           0.2801            0.26s\n",
      "         7           0.2680            0.26s\n",
      "         8           0.2541            0.25s\n",
      "         9           0.2486            0.25s\n",
      "        10           0.2382            0.24s\n",
      "        20           0.1936            0.19s\n",
      "        30           0.1755            0.12s\n",
      "        40           0.1680            0.06s\n",
      "        50           0.1638            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "70\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3397            0.29s\n",
      "         2           0.3196            0.29s\n",
      "         3           0.3041            0.28s\n",
      "         4           0.2904            0.26s\n",
      "         5           0.2808            0.27s\n",
      "         6           0.2636            0.26s\n",
      "         7           0.2413            0.25s\n",
      "         8           0.2238            0.25s\n",
      "         9           0.2192            0.24s\n",
      "        10           0.2052            0.24s\n",
      "        20           0.1640            0.21s\n",
      "        30           0.1183            0.14s\n",
      "        40           0.1111            0.07s\n",
      "        50           0.1033            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "71\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7744            0.07s\n",
      "         2           0.6075            0.06s\n",
      "         3           0.4618            0.06s\n",
      "         4           0.3541            0.06s\n",
      "         5           0.2818            0.06s\n",
      "         6           0.2180            0.06s\n",
      "         7           0.1692            0.06s\n",
      "         8           0.1323            0.06s\n",
      "         9           0.1057            0.06s\n",
      "        10           0.0829            0.05s\n",
      "        20           0.0137            0.02s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "72\n",
      "True\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3262            0.12s\n",
      "         2           0.3065            0.12s\n",
      "         3           0.2926            0.12s\n",
      "         4           0.2784            0.11s\n",
      "         5           0.2678            0.11s\n",
      "         6           0.2569            0.10s\n",
      "         7           0.2481            0.10s\n",
      "         8           0.2379            0.09s\n",
      "         9           0.2302            0.08s\n",
      "        10           0.2234            0.08s\n",
      "        20           0.1733            0.03s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "73\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3010            0.51s\n",
      "         2           0.2875            0.55s\n",
      "         3           0.2765            0.55s\n",
      "         4           0.2641            0.55s\n",
      "         5           0.2568            0.54s\n",
      "         6           0.2469            0.55s\n",
      "         7           0.2379            0.54s\n",
      "         8           0.2318            0.53s\n",
      "         9           0.2247            0.53s\n",
      "        10           0.2198            0.53s\n",
      "        20           0.1807            0.49s\n",
      "        30           0.1508            0.44s\n",
      "        40           0.1453            0.38s\n",
      "        50           0.1413            0.32s\n",
      "        60           0.1374            0.26s\n",
      "        70           0.1361            0.20s\n",
      "        80           0.1337            0.13s\n",
      "        90           0.1255            0.07s\n",
      "       100           0.1185            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "74\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3341            0.59s\n",
      "         2           0.3154            0.54s\n",
      "         3           0.2962            0.52s\n",
      "         4           0.2837            0.50s\n",
      "         5           0.2705            0.51s\n",
      "         6           0.2599            0.49s\n",
      "         7           0.2402            0.47s\n",
      "         8           0.2320            0.46s\n",
      "         9           0.2142            0.46s\n",
      "        10           0.2070            0.44s\n",
      "        20           0.1574            0.43s\n",
      "        30           0.1340            0.35s\n",
      "        40           0.1208            0.30s\n",
      "        50           0.1129            0.26s\n",
      "        60           0.1111            0.20s\n",
      "        70           0.1075            0.15s\n",
      "        80           0.1063            0.10s\n",
      "        90           0.1042            0.05s\n",
      "       100           0.1036            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "75\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3235            0.25s\n",
      "         2           0.3062            0.26s\n",
      "         3           0.2869            0.26s\n",
      "         4           0.2727            0.25s\n",
      "         5           0.2609            0.25s\n",
      "         6           0.2491            0.25s\n",
      "         7           0.2406            0.24s\n",
      "         8           0.2372            0.24s\n",
      "         9           0.2213            0.23s\n",
      "        10           0.2172            0.23s\n",
      "        20           0.1566            0.17s\n",
      "        30           0.1430            0.11s\n",
      "        40           0.1283            0.06s\n",
      "        50           0.1208            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "76\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8212            0.30s\n",
      "         2           0.6797            0.29s\n",
      "         3           0.5413            0.29s\n",
      "         4           0.4328            0.29s\n",
      "         5           0.3647            0.28s\n",
      "         6           0.2959            0.30s\n",
      "         7           0.2413            0.29s\n",
      "         8           0.1992            0.30s\n",
      "         9           0.1689            0.30s\n",
      "        10           0.1424            0.30s\n",
      "        20           0.0355            0.28s\n",
      "        30           0.0165            0.24s\n",
      "        40           0.0087            0.20s\n",
      "        50           0.0059            0.17s\n",
      "        60           0.0041            0.13s\n",
      "        70           0.0026            0.10s\n",
      "        80           0.0014            0.06s\n",
      "        90           0.0008            0.03s\n",
      "       100           0.0005            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "77\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7575            0.14s\n",
      "         2           0.5740            0.13s\n",
      "         3           0.4352            0.13s\n",
      "         4           0.3299            0.13s\n",
      "         5           0.2499            0.12s\n",
      "         6           0.1893            0.11s\n",
      "         7           0.1435            0.11s\n",
      "         8           0.1087            0.10s\n",
      "         9           0.0824            0.10s\n",
      "        10           0.0625            0.09s\n",
      "        20           0.0039            0.03s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "78\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3442            0.50s\n",
      "         2           0.3306            0.49s\n",
      "         3           0.3153            0.52s\n",
      "         4           0.3013            0.50s\n",
      "         5           0.2919            0.51s\n",
      "         6           0.2851            0.50s\n",
      "         7           0.2711            0.50s\n",
      "         8           0.2633            0.49s\n",
      "         9           0.2565            0.50s\n",
      "        10           0.2508            0.50s\n",
      "        20           0.1835            0.47s\n",
      "        30           0.1653            0.38s\n",
      "        40           0.1587            0.33s\n",
      "        50           0.1536            0.27s\n",
      "        60           0.1511            0.21s\n",
      "        70           0.1504            0.16s\n",
      "        80           0.1496            0.11s\n",
      "        90           0.1458            0.05s\n",
      "       100           0.1446            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "79\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3291            0.12s\n",
      "         2           0.3145            0.12s\n",
      "         3           0.2999            0.10s\n",
      "         4           0.2842            0.10s\n",
      "         5           0.2733            0.10s\n",
      "         6           0.2631            0.09s\n",
      "         7           0.2572            0.09s\n",
      "         8           0.2509            0.08s\n",
      "         9           0.2454            0.07s\n",
      "        10           0.2401            0.07s\n",
      "        20           0.1904            0.02s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "80\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3522            0.40s\n",
      "         2           0.3327            0.54s\n",
      "         3           0.3125            0.55s\n",
      "         4           0.2959            0.55s\n",
      "         5           0.2867            0.53s\n",
      "         6           0.2778            0.53s\n",
      "         7           0.2592            0.53s\n",
      "         8           0.2411            0.53s\n",
      "         9           0.2262            0.53s\n",
      "        10           0.2140            0.54s\n",
      "        20           0.1616            0.56s\n",
      "        30           0.1380            0.54s\n",
      "        40           0.1300            0.46s\n",
      "        50           0.1196            0.40s\n",
      "        60           0.1089            0.32s\n",
      "        70           0.1041            0.24s\n",
      "        80           0.1003            0.16s\n",
      "        90           0.0968            0.08s\n",
      "       100           0.0915            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "81\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3429            0.59s\n",
      "         2           0.3227            0.49s\n",
      "         3           0.3067            0.49s\n",
      "         4           0.2894            0.48s\n",
      "         5           0.2744            0.48s\n",
      "         6           0.2532            0.50s\n",
      "         7           0.2438            0.50s\n",
      "         8           0.2338            0.52s\n",
      "         9           0.2253            0.52s\n",
      "        10           0.2145            0.52s\n",
      "        20           0.1784            0.53s\n",
      "        30           0.1635            0.48s\n",
      "        40           0.1507            0.42s\n",
      "        50           0.1203            0.35s\n",
      "        60           0.1071            0.28s\n",
      "        70           0.0920            0.21s\n",
      "        80           0.0866            0.14s\n",
      "        90           0.0744            0.07s\n",
      "       100           0.0655            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "82\n",
      "False\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3109            0.59s\n",
      "         2           0.2824            0.54s\n",
      "         3           0.2646            0.49s\n",
      "         4           0.2506            0.46s\n",
      "         5           0.2373            0.48s\n",
      "         6           0.2242            0.50s\n",
      "         7           0.2134            0.50s\n",
      "         8           0.2077            0.52s\n",
      "         9           0.1981            0.52s\n",
      "        10           0.1861            0.50s\n",
      "        20           0.1516            0.45s\n",
      "        30           0.1331            0.39s\n",
      "        40           0.1293            0.34s\n",
      "        50           0.1262            0.29s\n",
      "        60           0.1102            0.23s\n",
      "        70           0.1044            0.17s\n",
      "        80           0.1029            0.12s\n",
      "        90           0.0843            0.06s\n",
      "       100           0.0630            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "83\n",
      "False\n",
      "True\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3231            0.40s\n",
      "         2           0.3062            0.39s\n",
      "         3           0.2900            0.39s\n",
      "         4           0.2734            0.40s\n",
      "         5           0.2623            0.41s\n",
      "         6           0.2508            0.41s\n",
      "         7           0.2422            0.41s\n",
      "         8           0.2310            0.40s\n",
      "         9           0.2239            0.39s\n",
      "        10           0.2154            0.39s\n",
      "        20           0.1596            0.34s\n",
      "        30           0.1504            0.28s\n",
      "        40           0.1447            0.22s\n",
      "        50           0.1429            0.16s\n",
      "        60           0.1324            0.10s\n",
      "        70           0.1240            0.05s\n",
      "        80           0.1129            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "84\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgb\n",
      "Fitting 3 folds for each of 800 candidates, totalling 2400 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3585            0.40s\n",
      "         2           0.3386            0.44s\n",
      "         3           0.3221            0.49s\n",
      "         4           0.3086            0.48s\n",
      "         5           0.2933            0.53s\n",
      "         6           0.2863            0.55s\n",
      "         7           0.2672            0.56s\n",
      "         8           0.2506            0.60s\n",
      "         9           0.2359            0.60s\n",
      "        10           0.2282            0.60s\n",
      "        20           0.1890            0.59s\n",
      "        30           0.1613            0.56s\n",
      "        40           0.1461            0.48s\n",
      "        50           0.1198            0.42s\n",
      "        60           0.1136            0.33s\n",
      "        70           0.1011            0.25s\n",
      "        80           0.0930            0.17s\n",
      "        90           0.0882            0.08s\n",
      "       100           0.0854            0.00s\n",
      "\n",
      "mlp\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "85\n",
      "True\n",
      "False\n",
      "\n",
      "RF\n",
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQcc_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTD\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCodiga_debt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 107\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     93\u001b[0m rf_param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [ \u001b[38;5;28;01mFalse\u001b[39;00m],\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m80\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    103\u001b[0m }\n\u001b[0;32m    105\u001b[0m rf_grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m rf, param_grid \u001b[38;5;241m=\u001b[39m rf_param_grid, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[43mrf_grid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m rf_grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    111\u001b[0m rf_pred \u001b[38;5;241m=\u001b[39m best_rf\u001b[38;5;241m.\u001b[39mpredict(X_test_n)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = run(Qcc_quant, TD['Codiga_debt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('CO_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58baa2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
